{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patent Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Sequential\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding\n",
    "from tensorflow.keras.layers import Dropout, Activation, Bidirectional, GlobalMaxPool1D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from tensorflow.keras.preprocessing import text, sequence\n",
    "\n",
    "import spacy\n",
    "from gensim.models import Word2Vec\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "\n",
    "from pandas.io.json import json_normalize\n",
    "import pickle\n",
    "from collections import ChainMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import data from PatentsView API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_colwidth', -1)\n",
    "pd.options.display.max_columns = 50\n",
    "pd.set_option('display.max_rows', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patents endpoint\n",
    "endpoint_url = 'http://www.patentsview.org/api/patents/query'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build list from file of possible fields that endpoint request will return\n",
    "df = pd.read_excel(\"data/patents_view_patents_fields.xlsx\")\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n",
    "pat_fields = df.api_field_name.values.tolist()\n",
    "len(pat_fields) # 184 possible fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct and run GET request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass directly into browser\n",
    "# http://www.patentsview.org/api/patents/query?q={\"_text_any\":{\"patent_abstract\":\"natural langugage processing\"}}\n",
    "# patents = []\n",
    "\n",
    "query={\"_or\":[{\"_text_phrase\":{\"patent_title\":\"natural language\"}},{\"_text_phrase\":{\"patent_abstract\":\"natural language\"}}]}\n",
    "fields=pat_fields\n",
    "options={\"per_page\":2500}\n",
    "sort=[{\"patent_date\":\"desc\"}]\n",
    "\n",
    "params={'q': json.dumps(query),\n",
    "        'f': json.dumps(fields),\n",
    "        'o': json.dumps(options),\n",
    "        's': json.dumps(sort)}\n",
    "\n",
    "# options (works) = {\"page\":1, \"per_page\":10}\n",
    "\n",
    "# other queries - uncomment to run\n",
    "# query (works) ={\"_text_all\":{\"patent_abstract\":\"nlp\"}},{\"_text_all\":{\"patent_abstract\":\"natural language processing\"}}]}\n",
    "# 529 results: {\"_text_phrase\":{\"patent_abstract\":\"natural language processing\"}} \n",
    "# 858 results: {\"_text_all\":{\"patent_abstract\":\"natural language processing\"}} \n",
    "# 957 results: query={\"_or\":[{\"_text_all\":{\"patent_title\":\"natural language processing\"}},{\"_text_all\":{\"patent_abstract\":\"natural language processing\"}}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# request and results\n",
    "resp = requests.get(endpoint_url, params=params)\n",
    "results = resp.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect results from GET request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status code: 200 ; reason: OK\n",
      "total_patent_count: 2482 ; patents_per_page: 2482\n"
     ]
    }
   ],
   "source": [
    "# extract metadata from response\n",
    "print(\"status code:\", resp.status_code,';', \"reason:\", resp.reason)\n",
    "total_patent_count = results[\"total_patent_count\"]\n",
    "patents_per_page = results['count']\n",
    "print(\"total_patent_count:\",total_patent_count,';', \"patents_per_page:\", patents_per_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IPCs</th>\n",
       "      <th>application_citations</th>\n",
       "      <th>applications</th>\n",
       "      <th>assignees</th>\n",
       "      <th>cited_patents</th>\n",
       "      <th>citedby_patents</th>\n",
       "      <th>cpcs</th>\n",
       "      <th>detail_desc_length</th>\n",
       "      <th>examiners</th>\n",
       "      <th>foreign_priority</th>\n",
       "      <th>gov_interests</th>\n",
       "      <th>inventors</th>\n",
       "      <th>lawyers</th>\n",
       "      <th>nbers</th>\n",
       "      <th>patent_abstract</th>\n",
       "      <th>patent_average_processing_time</th>\n",
       "      <th>patent_date</th>\n",
       "      <th>patent_firstnamed_assignee_city</th>\n",
       "      <th>patent_firstnamed_assignee_country</th>\n",
       "      <th>patent_firstnamed_assignee_id</th>\n",
       "      <th>patent_firstnamed_assignee_latitude</th>\n",
       "      <th>patent_firstnamed_assignee_location_id</th>\n",
       "      <th>patent_firstnamed_assignee_longitude</th>\n",
       "      <th>patent_firstnamed_assignee_state</th>\n",
       "      <th>patent_firstnamed_inventor_city</th>\n",
       "      <th>patent_firstnamed_inventor_country</th>\n",
       "      <th>patent_firstnamed_inventor_id</th>\n",
       "      <th>patent_firstnamed_inventor_latitude</th>\n",
       "      <th>patent_firstnamed_inventor_location_id</th>\n",
       "      <th>patent_firstnamed_inventor_longitude</th>\n",
       "      <th>patent_firstnamed_inventor_state</th>\n",
       "      <th>patent_kind</th>\n",
       "      <th>patent_num_cited_by_us_patents</th>\n",
       "      <th>patent_num_claims</th>\n",
       "      <th>patent_num_combined_citations</th>\n",
       "      <th>patent_num_foreign_citations</th>\n",
       "      <th>patent_num_us_application_citations</th>\n",
       "      <th>patent_num_us_patent_citations</th>\n",
       "      <th>patent_number</th>\n",
       "      <th>patent_processing_time</th>\n",
       "      <th>patent_title</th>\n",
       "      <th>patent_type</th>\n",
       "      <th>patent_year</th>\n",
       "      <th>pct_data</th>\n",
       "      <th>rawinventors</th>\n",
       "      <th>uspcs</th>\n",
       "      <th>wipos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'ipc_action_date': '2019-03-12', 'ipc_class'...</td>\n",
       "      <td>[{'appcit_app_number': '2002/20020077823', 'ap...</td>\n",
       "      <td>[{'app_country': 'US', 'app_date': '2013-07-26...</td>\n",
       "      <td>[{'assignee_city': 'Burlington', 'assignee_cou...</td>\n",
       "      <td>[{'cited_patent_category': 'cited by examiner'...</td>\n",
       "      <td>[{'citedby_patent_category': None, 'citedby_pa...</td>\n",
       "      <td>[{'cpc_category': None, 'cpc_first_seen_date':...</td>\n",
       "      <td>11570</td>\n",
       "      <td>[{'examiner_first_name': 'Michael N', 'examine...</td>\n",
       "      <td>[{'forprior_country': None, 'forprior_date': N...</td>\n",
       "      <td>[{'govint_contract_award_number': None, 'govin...</td>\n",
       "      <td>[{'inventor_city': 'Newton', 'inventor_country...</td>\n",
       "      <td>[{'lawyer_first_name': None, 'lawyer_first_see...</td>\n",
       "      <td>[{'nber_category_id': None, 'nber_category_tit...</td>\n",
       "      <td>Designing a natural language understanding (NL...</td>\n",
       "      <td>None</td>\n",
       "      <td>2019-03-12</td>\n",
       "      <td>Burlington</td>\n",
       "      <td>US</td>\n",
       "      <td>org_ID497r4tFbCIaMBjGAST</td>\n",
       "      <td>42.5047</td>\n",
       "      <td>42.5047|-71.1961</td>\n",
       "      <td>-71.1961</td>\n",
       "      <td>MA</td>\n",
       "      <td>Newton</td>\n",
       "      <td>US</td>\n",
       "      <td>7788103-1</td>\n",
       "      <td>42.3369</td>\n",
       "      <td>42.3369|-71.2097</td>\n",
       "      <td>-71.2097</td>\n",
       "      <td>MA</td>\n",
       "      <td>B2</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>10229106</td>\n",
       "      <td>2055</td>\n",
       "      <td>Initializing a workspace for building a natura...</td>\n",
       "      <td>utility</td>\n",
       "      <td>2019</td>\n",
       "      <td>[{'pct_102_date': None, 'pct_371_date': None, ...</td>\n",
       "      <td>[{'rawinventor_first_name': 'Jeffrey N.', 'raw...</td>\n",
       "      <td>[{'uspc_first_seen_date': None, 'uspc_last_see...</td>\n",
       "      <td>[{'wipo_field_id': None, 'wipo_field_title': N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'ipc_action_date': '2019-03-12', 'ipc_class'...</td>\n",
       "      <td>[{'appcit_app_number': '2002/20020138265', 'ap...</td>\n",
       "      <td>[{'app_country': 'US', 'app_date': '2017-09-11...</td>\n",
       "      <td>[{'assignee_city': 'Mountain View', 'assignee_...</td>\n",
       "      <td>[{'cited_patent_category': 'cited by applicant...</td>\n",
       "      <td>[{'citedby_patent_category': None, 'citedby_pa...</td>\n",
       "      <td>[{'cpc_category': None, 'cpc_first_seen_date':...</td>\n",
       "      <td>28118</td>\n",
       "      <td>[{'examiner_first_name': 'Shreyans A', 'examin...</td>\n",
       "      <td>[{'forprior_country': None, 'forprior_date': N...</td>\n",
       "      <td>[{'govint_contract_award_number': None, 'govin...</td>\n",
       "      <td>[{'inventor_city': 'Adliswil', 'inventor_count...</td>\n",
       "      <td>[{'lawyer_first_name': None, 'lawyer_first_see...</td>\n",
       "      <td>[{'nber_category_id': None, 'nber_category_tit...</td>\n",
       "      <td>Methods, systems, and apparatus, including com...</td>\n",
       "      <td>None</td>\n",
       "      <td>2019-03-12</td>\n",
       "      <td>Mountain View</td>\n",
       "      <td>US</td>\n",
       "      <td>org_p6ofWD2xFNSnyYkj6wpA</td>\n",
       "      <td>37.3861</td>\n",
       "      <td>37.3861|-122.0828</td>\n",
       "      <td>-122.083</td>\n",
       "      <td>CA</td>\n",
       "      <td>Adliswil</td>\n",
       "      <td>CH</td>\n",
       "      <td>8352247-1</td>\n",
       "      <td>47.3119</td>\n",
       "      <td>47.3119|8.5287</td>\n",
       "      <td>8.5287</td>\n",
       "      <td>None</td>\n",
       "      <td>B1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>10229109</td>\n",
       "      <td>547</td>\n",
       "      <td>Allowing spelling of arbitrary words</td>\n",
       "      <td>utility</td>\n",
       "      <td>2019</td>\n",
       "      <td>[{'pct_102_date': None, 'pct_371_date': None, ...</td>\n",
       "      <td>[{'rawinventor_first_name': 'Evgeny A.', 'rawi...</td>\n",
       "      <td>[{'uspc_first_seen_date': None, 'uspc_last_see...</td>\n",
       "      <td>[{'wipo_field_id': None, 'wipo_field_title': N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'ipc_action_date': '2019-03-12', 'ipc_class'...</td>\n",
       "      <td>[{'appcit_app_number': '2001/20010029455', 'ap...</td>\n",
       "      <td>[{'app_country': 'US', 'app_date': '2016-09-28...</td>\n",
       "      <td>[{'assignee_city': 'Seattle', 'assignee_countr...</td>\n",
       "      <td>[{'cited_patent_category': 'cited by applicant...</td>\n",
       "      <td>[{'citedby_patent_category': None, 'citedby_pa...</td>\n",
       "      <td>[{'cpc_category': None, 'cpc_first_seen_date':...</td>\n",
       "      <td>119654</td>\n",
       "      <td>[{'examiner_first_name': 'Jialong', 'examiner_...</td>\n",
       "      <td>[{'forprior_country': None, 'forprior_date': N...</td>\n",
       "      <td>[{'govint_contract_award_number': None, 'govin...</td>\n",
       "      <td>[{'inventor_city': 'Seattle', 'inventor_countr...</td>\n",
       "      <td>[{'lawyer_first_name': None, 'lawyer_first_see...</td>\n",
       "      <td>[{'nber_category_id': None, 'nber_category_tit...</td>\n",
       "      <td>A content management system (CMS) and a transl...</td>\n",
       "      <td>None</td>\n",
       "      <td>2019-03-12</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>US</td>\n",
       "      <td>org_Vbc6obpnxWM42d0HjlXY</td>\n",
       "      <td>47.6064</td>\n",
       "      <td>47.6064|-122.3308</td>\n",
       "      <td>-122.331</td>\n",
       "      <td>WA</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>US</td>\n",
       "      <td>9177341-1</td>\n",
       "      <td>47.6064</td>\n",
       "      <td>47.6064|-122.3308</td>\n",
       "      <td>-122.331</td>\n",
       "      <td>WA</td>\n",
       "      <td>B1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>26</td>\n",
       "      <td>10229113</td>\n",
       "      <td>895</td>\n",
       "      <td>Leveraging content dimensions during the trans...</td>\n",
       "      <td>utility</td>\n",
       "      <td>2019</td>\n",
       "      <td>[{'pct_102_date': None, 'pct_371_date': None, ...</td>\n",
       "      <td>[{'rawinventor_first_name': 'Thibault Pierre',...</td>\n",
       "      <td>[{'uspc_first_seen_date': None, 'uspc_last_see...</td>\n",
       "      <td>[{'wipo_field_id': None, 'wipo_field_title': N...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                IPCs  \\\n",
       "0  [{'ipc_action_date': '2019-03-12', 'ipc_class'...   \n",
       "1  [{'ipc_action_date': '2019-03-12', 'ipc_class'...   \n",
       "2  [{'ipc_action_date': '2019-03-12', 'ipc_class'...   \n",
       "\n",
       "                               application_citations  \\\n",
       "0  [{'appcit_app_number': '2002/20020077823', 'ap...   \n",
       "1  [{'appcit_app_number': '2002/20020138265', 'ap...   \n",
       "2  [{'appcit_app_number': '2001/20010029455', 'ap...   \n",
       "\n",
       "                                        applications  \\\n",
       "0  [{'app_country': 'US', 'app_date': '2013-07-26...   \n",
       "1  [{'app_country': 'US', 'app_date': '2017-09-11...   \n",
       "2  [{'app_country': 'US', 'app_date': '2016-09-28...   \n",
       "\n",
       "                                           assignees  \\\n",
       "0  [{'assignee_city': 'Burlington', 'assignee_cou...   \n",
       "1  [{'assignee_city': 'Mountain View', 'assignee_...   \n",
       "2  [{'assignee_city': 'Seattle', 'assignee_countr...   \n",
       "\n",
       "                                       cited_patents  \\\n",
       "0  [{'cited_patent_category': 'cited by examiner'...   \n",
       "1  [{'cited_patent_category': 'cited by applicant...   \n",
       "2  [{'cited_patent_category': 'cited by applicant...   \n",
       "\n",
       "                                     citedby_patents  \\\n",
       "0  [{'citedby_patent_category': None, 'citedby_pa...   \n",
       "1  [{'citedby_patent_category': None, 'citedby_pa...   \n",
       "2  [{'citedby_patent_category': None, 'citedby_pa...   \n",
       "\n",
       "                                                cpcs detail_desc_length  \\\n",
       "0  [{'cpc_category': None, 'cpc_first_seen_date':...              11570   \n",
       "1  [{'cpc_category': None, 'cpc_first_seen_date':...              28118   \n",
       "2  [{'cpc_category': None, 'cpc_first_seen_date':...             119654   \n",
       "\n",
       "                                           examiners  \\\n",
       "0  [{'examiner_first_name': 'Michael N', 'examine...   \n",
       "1  [{'examiner_first_name': 'Shreyans A', 'examin...   \n",
       "2  [{'examiner_first_name': 'Jialong', 'examiner_...   \n",
       "\n",
       "                                    foreign_priority  \\\n",
       "0  [{'forprior_country': None, 'forprior_date': N...   \n",
       "1  [{'forprior_country': None, 'forprior_date': N...   \n",
       "2  [{'forprior_country': None, 'forprior_date': N...   \n",
       "\n",
       "                                       gov_interests  \\\n",
       "0  [{'govint_contract_award_number': None, 'govin...   \n",
       "1  [{'govint_contract_award_number': None, 'govin...   \n",
       "2  [{'govint_contract_award_number': None, 'govin...   \n",
       "\n",
       "                                           inventors  \\\n",
       "0  [{'inventor_city': 'Newton', 'inventor_country...   \n",
       "1  [{'inventor_city': 'Adliswil', 'inventor_count...   \n",
       "2  [{'inventor_city': 'Seattle', 'inventor_countr...   \n",
       "\n",
       "                                             lawyers  \\\n",
       "0  [{'lawyer_first_name': None, 'lawyer_first_see...   \n",
       "1  [{'lawyer_first_name': None, 'lawyer_first_see...   \n",
       "2  [{'lawyer_first_name': None, 'lawyer_first_see...   \n",
       "\n",
       "                                               nbers  \\\n",
       "0  [{'nber_category_id': None, 'nber_category_tit...   \n",
       "1  [{'nber_category_id': None, 'nber_category_tit...   \n",
       "2  [{'nber_category_id': None, 'nber_category_tit...   \n",
       "\n",
       "                                     patent_abstract  \\\n",
       "0  Designing a natural language understanding (NL...   \n",
       "1  Methods, systems, and apparatus, including com...   \n",
       "2  A content management system (CMS) and a transl...   \n",
       "\n",
       "  patent_average_processing_time patent_date patent_firstnamed_assignee_city  \\\n",
       "0                           None  2019-03-12                      Burlington   \n",
       "1                           None  2019-03-12                   Mountain View   \n",
       "2                           None  2019-03-12                         Seattle   \n",
       "\n",
       "  patent_firstnamed_assignee_country patent_firstnamed_assignee_id  \\\n",
       "0                                 US      org_ID497r4tFbCIaMBjGAST   \n",
       "1                                 US      org_p6ofWD2xFNSnyYkj6wpA   \n",
       "2                                 US      org_Vbc6obpnxWM42d0HjlXY   \n",
       "\n",
       "  patent_firstnamed_assignee_latitude patent_firstnamed_assignee_location_id  \\\n",
       "0                             42.5047                       42.5047|-71.1961   \n",
       "1                             37.3861                      37.3861|-122.0828   \n",
       "2                             47.6064                      47.6064|-122.3308   \n",
       "\n",
       "  patent_firstnamed_assignee_longitude patent_firstnamed_assignee_state  \\\n",
       "0                             -71.1961                               MA   \n",
       "1                             -122.083                               CA   \n",
       "2                             -122.331                               WA   \n",
       "\n",
       "  patent_firstnamed_inventor_city patent_firstnamed_inventor_country  \\\n",
       "0                          Newton                                 US   \n",
       "1                        Adliswil                                 CH   \n",
       "2                         Seattle                                 US   \n",
       "\n",
       "  patent_firstnamed_inventor_id patent_firstnamed_inventor_latitude  \\\n",
       "0                     7788103-1                             42.3369   \n",
       "1                     8352247-1                             47.3119   \n",
       "2                     9177341-1                             47.6064   \n",
       "\n",
       "  patent_firstnamed_inventor_location_id patent_firstnamed_inventor_longitude  \\\n",
       "0                       42.3369|-71.2097                             -71.2097   \n",
       "1                         47.3119|8.5287                               8.5287   \n",
       "2                      47.6064|-122.3308                             -122.331   \n",
       "\n",
       "  patent_firstnamed_inventor_state patent_kind patent_num_cited_by_us_patents  \\\n",
       "0                               MA          B2                              0   \n",
       "1                             None          B1                              0   \n",
       "2                               WA          B1                              0   \n",
       "\n",
       "  patent_num_claims patent_num_combined_citations  \\\n",
       "0                19                            31   \n",
       "1                20                            15   \n",
       "2                20                            74   \n",
       "\n",
       "  patent_num_foreign_citations patent_num_us_application_citations  \\\n",
       "0                            0                                  26   \n",
       "1                            0                                   7   \n",
       "2                            0                                  48   \n",
       "\n",
       "  patent_num_us_patent_citations patent_number patent_processing_time  \\\n",
       "0                              5      10229106                   2055   \n",
       "1                              8      10229109                    547   \n",
       "2                             26      10229113                    895   \n",
       "\n",
       "                                        patent_title patent_type patent_year  \\\n",
       "0  Initializing a workspace for building a natura...     utility        2019   \n",
       "1               Allowing spelling of arbitrary words     utility        2019   \n",
       "2  Leveraging content dimensions during the trans...     utility        2019   \n",
       "\n",
       "                                            pct_data  \\\n",
       "0  [{'pct_102_date': None, 'pct_371_date': None, ...   \n",
       "1  [{'pct_102_date': None, 'pct_371_date': None, ...   \n",
       "2  [{'pct_102_date': None, 'pct_371_date': None, ...   \n",
       "\n",
       "                                        rawinventors  \\\n",
       "0  [{'rawinventor_first_name': 'Jeffrey N.', 'raw...   \n",
       "1  [{'rawinventor_first_name': 'Evgeny A.', 'rawi...   \n",
       "2  [{'rawinventor_first_name': 'Thibault Pierre',...   \n",
       "\n",
       "                                               uspcs  \\\n",
       "0  [{'uspc_first_seen_date': None, 'uspc_last_see...   \n",
       "1  [{'uspc_first_seen_date': None, 'uspc_last_see...   \n",
       "2  [{'uspc_first_seen_date': None, 'uspc_last_see...   \n",
       "\n",
       "                                               wipos  \n",
       "0  [{'wipo_field_id': None, 'wipo_field_title': N...  \n",
       "1  [{'wipo_field_id': None, 'wipo_field_title': N...  \n",
       "2  [{'wipo_field_id': None, 'wipo_field_title': N...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract data from response\n",
    "data = results['patents']\n",
    "# data[0]\n",
    "df = pd.DataFrame(data)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ser = df_assignees['assignee_id'].apply(pd.Series)\n",
    "# len(ser)\n",
    "# ser.duplicated()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subset dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['IPCs', 'application_citations', 'applications', 'assignees',\n",
       "       'cited_patents', 'citedby_patents', 'cpcs', 'detail_desc_length',\n",
       "       'examiners', 'foreign_priority', 'gov_interests', 'inventors',\n",
       "       'lawyers', 'nbers', 'patent_abstract', 'patent_average_processing_time',\n",
       "       'patent_date', 'patent_firstnamed_assignee_city',\n",
       "       'patent_firstnamed_assignee_country', 'patent_firstnamed_assignee_id',\n",
       "       'patent_firstnamed_assignee_latitude',\n",
       "       'patent_firstnamed_assignee_location_id',\n",
       "       'patent_firstnamed_assignee_longitude',\n",
       "       'patent_firstnamed_assignee_state', 'patent_firstnamed_inventor_city',\n",
       "       'patent_firstnamed_inventor_country', 'patent_firstnamed_inventor_id',\n",
       "       'patent_firstnamed_inventor_latitude',\n",
       "       'patent_firstnamed_inventor_location_id',\n",
       "       'patent_firstnamed_inventor_longitude',\n",
       "       'patent_firstnamed_inventor_state', 'patent_kind',\n",
       "       'patent_num_cited_by_us_patents', 'patent_num_claims',\n",
       "       'patent_num_combined_citations', 'patent_num_foreign_citations',\n",
       "       'patent_num_us_application_citations', 'patent_num_us_patent_citations',\n",
       "       'patent_number', 'patent_processing_time', 'patent_title',\n",
       "       'patent_type', 'patent_year', 'pct_data', 'rawinventors', 'uspcs',\n",
       "       'wipos'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patent_number</th>\n",
       "      <th>patent_date</th>\n",
       "      <th>patent_title</th>\n",
       "      <th>patent_abstract</th>\n",
       "      <th>patent_firstnamed_assignee_id</th>\n",
       "      <th>patent_year</th>\n",
       "      <th>patent_type</th>\n",
       "      <th>patent_kind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10229106</td>\n",
       "      <td>2019-03-12</td>\n",
       "      <td>Initializing a workspace for building a natura...</td>\n",
       "      <td>Designing a natural language understanding (NL...</td>\n",
       "      <td>org_ID497r4tFbCIaMBjGAST</td>\n",
       "      <td>2019</td>\n",
       "      <td>utility</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10229109</td>\n",
       "      <td>2019-03-12</td>\n",
       "      <td>Allowing spelling of arbitrary words</td>\n",
       "      <td>Methods, systems, and apparatus, including com...</td>\n",
       "      <td>org_p6ofWD2xFNSnyYkj6wpA</td>\n",
       "      <td>2019</td>\n",
       "      <td>utility</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10229113</td>\n",
       "      <td>2019-03-12</td>\n",
       "      <td>Leveraging content dimensions during the trans...</td>\n",
       "      <td>A content management system (CMS) and a transl...</td>\n",
       "      <td>org_Vbc6obpnxWM42d0HjlXY</td>\n",
       "      <td>2019</td>\n",
       "      <td>utility</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  patent_number patent_date  \\\n",
       "0      10229106  2019-03-12   \n",
       "1      10229109  2019-03-12   \n",
       "2      10229113  2019-03-12   \n",
       "\n",
       "                                        patent_title  \\\n",
       "0  Initializing a workspace for building a natura...   \n",
       "1               Allowing spelling of arbitrary words   \n",
       "2  Leveraging content dimensions during the trans...   \n",
       "\n",
       "                                     patent_abstract  \\\n",
       "0  Designing a natural language understanding (NL...   \n",
       "1  Methods, systems, and apparatus, including com...   \n",
       "2  A content management system (CMS) and a transl...   \n",
       "\n",
       "  patent_firstnamed_assignee_id patent_year patent_type patent_kind  \n",
       "0      org_ID497r4tFbCIaMBjGAST        2019     utility          B2  \n",
       "1      org_p6ofWD2xFNSnyYkj6wpA        2019     utility          B1  \n",
       "2      org_Vbc6obpnxWM42d0HjlXY        2019     utility          B1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['patent_number', \n",
    "         'patent_date', \n",
    "         'patent_title',\n",
    "         'patent_abstract', \n",
    "         'patent_firstnamed_assignee_id', \n",
    "         'patent_year', \n",
    "         'patent_type', \n",
    "         'patent_kind']]\n",
    "df.head(3)\n",
    "\n",
    "# other field options - uncomment to use\n",
    "# df = df[['patent_number', \n",
    "#          'patent_date', \n",
    "#          'patent_title',\n",
    "#          'patent_abstract', \n",
    "#          'patent_firstnamed_assignee_id',\n",
    "#          'patent_firstnamed_assignee_location_id',\n",
    "#          'patent_firstnamed_assignee_latitude',\n",
    "#          'patent_firstnamed_assignee_longitude',\n",
    "#          'patent_firstnamed_assignee_city',\n",
    "#          'patent_firstnamed_assignee_state',\n",
    "#          'patent_firstnamed_assignee_country', \n",
    "#          'patent_firstnamed_inventor_id',\n",
    "#          'patent_firstnamed_inventor_location_id',\n",
    "#          'patent_firstnamed_inventor_latitude',\n",
    "#          'patent_firstnamed_inventor_longitude',\n",
    "#          'patent_firstnamed_inventor_city',\n",
    "#          'patent_firstnamed_inventor_state',\n",
    "#          'patent_firstnamed_inventor_country',\n",
    "#          'patent_year', \n",
    "#          'patent_type', \n",
    "#          'patent_kind',\n",
    "#          'patent_processing_time', \n",
    "#          'patent_num_us_application_citations', \n",
    "#          'patent_num_us_patent_citations', \n",
    "#          'patent_num_foreign_citations', \n",
    "#          'patent_num_combined_citations', \n",
    "#          'patent_num_claims', \n",
    "#          'patent_num_cited_by_us_patents',\n",
    "#          'detail_desc_length']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2482"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['patent_number', 'patent_date', 'patent_title', 'patent_abstract',\n",
       "       'patent_firstnamed_assignee_id', 'patent_year', 'patent_type',\n",
       "       'patent_kind'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Initializing a workspace for building a natura...\n",
       "1    Allowing spelling of arbitrary words Methods, ...\n",
       "2    Leveraging content dimensions during the trans...\n",
       "Name: patent_title_abstract, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['patent_title_abstract'] = df.patent_title + ' ' + df.patent_abstract\n",
    "df.patent_title_abstract.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "561"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 561 different assignees\n",
    "len(df.patent_firstnamed_assignee_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "org_q9Bn28RHhpYrQjKvraAH    497\n",
       "org_JZguWDMfFOBX2wBI9pnD    129\n",
       "org_ID497r4tFbCIaMBjGAST     88\n",
       "org_rDyHZBYWMcBEtnkHt05L     80\n",
       "org_p6ofWD2xFNSnyYkj6wpA     57\n",
       "org_EilEWQcC6UiqHcSGx9mb     56\n",
       "org_ccMMcUijAIsKIxUqMTyP     49\n",
       "org_Vbc6obpnxWM42d0HjlXY     41\n",
       "org_9D8x1qL3IRASp6GG7Glu     29\n",
       "org_2wAdIFKssfcLHpZq0u4H     26\n",
       "Name: patent_firstnamed_assignee_id, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.patent_firstnamed_assignee_id.value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of assignees with > 20 patents in df dataset\n",
    "assignees_list = ['org_q9Bn28RHhpYrQjKvraAH', 'org_JZguWDMfFOBX2wBI9pnD', 'org_ID497r4tFbCIaMBjGAST', \n",
    "                  'org_rDyHZBYWMcBEtnkHt05L', 'org_p6ofWD2xFNSnyYkj6wpA', 'org_EilEWQcC6UiqHcSGx9mb',\n",
    "                  'org_ccMMcUijAIsKIxUqMTyP', 'org_Vbc6obpnxWM42d0HjlXY', 'org_9D8x1qL3IRASp6GG7Glu',\n",
    "                  'org_2wAdIFKssfcLHpZq0u4H', 'org_iwO2oOJ6VIBd9fAuP7G6', 'org_70D1lR89kQnFiCFdJ6s5',\n",
    "                  'org_vojVnDkT9CamDETqbqJC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patent_number</th>\n",
       "      <th>patent_date</th>\n",
       "      <th>patent_title</th>\n",
       "      <th>patent_abstract</th>\n",
       "      <th>patent_firstnamed_assignee_id</th>\n",
       "      <th>patent_year</th>\n",
       "      <th>patent_type</th>\n",
       "      <th>patent_kind</th>\n",
       "      <th>patent_title_abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10229106</td>\n",
       "      <td>2019-03-12</td>\n",
       "      <td>Initializing a workspace for building a natura...</td>\n",
       "      <td>Designing a natural language understanding (NL...</td>\n",
       "      <td>org_ID497r4tFbCIaMBjGAST</td>\n",
       "      <td>2019</td>\n",
       "      <td>utility</td>\n",
       "      <td>B2</td>\n",
       "      <td>Initializing a workspace for building a natura...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10229109</td>\n",
       "      <td>2019-03-12</td>\n",
       "      <td>Allowing spelling of arbitrary words</td>\n",
       "      <td>Methods, systems, and apparatus, including com...</td>\n",
       "      <td>org_p6ofWD2xFNSnyYkj6wpA</td>\n",
       "      <td>2019</td>\n",
       "      <td>utility</td>\n",
       "      <td>B1</td>\n",
       "      <td>Allowing spelling of arbitrary words Methods, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10229113</td>\n",
       "      <td>2019-03-12</td>\n",
       "      <td>Leveraging content dimensions during the trans...</td>\n",
       "      <td>A content management system (CMS) and a transl...</td>\n",
       "      <td>org_Vbc6obpnxWM42d0HjlXY</td>\n",
       "      <td>2019</td>\n",
       "      <td>utility</td>\n",
       "      <td>B1</td>\n",
       "      <td>Leveraging content dimensions during the trans...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  patent_number patent_date  \\\n",
       "0      10229106  2019-03-12   \n",
       "1      10229109  2019-03-12   \n",
       "2      10229113  2019-03-12   \n",
       "\n",
       "                                        patent_title  \\\n",
       "0  Initializing a workspace for building a natura...   \n",
       "1               Allowing spelling of arbitrary words   \n",
       "2  Leveraging content dimensions during the trans...   \n",
       "\n",
       "                                     patent_abstract  \\\n",
       "0  Designing a natural language understanding (NL...   \n",
       "1  Methods, systems, and apparatus, including com...   \n",
       "2  A content management system (CMS) and a transl...   \n",
       "\n",
       "  patent_firstnamed_assignee_id patent_year patent_type patent_kind  \\\n",
       "0      org_ID497r4tFbCIaMBjGAST        2019     utility          B2   \n",
       "1      org_p6ofWD2xFNSnyYkj6wpA        2019     utility          B1   \n",
       "2      org_Vbc6obpnxWM42d0HjlXY        2019     utility          B1   \n",
       "\n",
       "                               patent_title_abstract  \n",
       "0  Initializing a workspace for building a natura...  \n",
       "1  Allowing spelling of arbitrary words Methods, ...  \n",
       "2  Leveraging content dimensions during the trans...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_20pats = df[df['patent_firstnamed_assignee_id'].isin(assignees_list) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patent_number</th>\n",
       "      <th>patent_date</th>\n",
       "      <th>patent_title</th>\n",
       "      <th>patent_abstract</th>\n",
       "      <th>patent_firstnamed_assignee_id</th>\n",
       "      <th>patent_year</th>\n",
       "      <th>patent_type</th>\n",
       "      <th>patent_kind</th>\n",
       "      <th>patent_title_abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10229106</td>\n",
       "      <td>2019-03-12</td>\n",
       "      <td>Initializing a workspace for building a natura...</td>\n",
       "      <td>Designing a natural language understanding (NL...</td>\n",
       "      <td>org_ID497r4tFbCIaMBjGAST</td>\n",
       "      <td>2019</td>\n",
       "      <td>utility</td>\n",
       "      <td>B2</td>\n",
       "      <td>Initializing a workspace for building a natura...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10229109</td>\n",
       "      <td>2019-03-12</td>\n",
       "      <td>Allowing spelling of arbitrary words</td>\n",
       "      <td>Methods, systems, and apparatus, including com...</td>\n",
       "      <td>org_p6ofWD2xFNSnyYkj6wpA</td>\n",
       "      <td>2019</td>\n",
       "      <td>utility</td>\n",
       "      <td>B1</td>\n",
       "      <td>Allowing spelling of arbitrary words Methods, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10229113</td>\n",
       "      <td>2019-03-12</td>\n",
       "      <td>Leveraging content dimensions during the trans...</td>\n",
       "      <td>A content management system (CMS) and a transl...</td>\n",
       "      <td>org_Vbc6obpnxWM42d0HjlXY</td>\n",
       "      <td>2019</td>\n",
       "      <td>utility</td>\n",
       "      <td>B1</td>\n",
       "      <td>Leveraging content dimensions during the trans...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  patent_number patent_date  \\\n",
       "0      10229106  2019-03-12   \n",
       "1      10229109  2019-03-12   \n",
       "2      10229113  2019-03-12   \n",
       "\n",
       "                                        patent_title  \\\n",
       "0  Initializing a workspace for building a natura...   \n",
       "1               Allowing spelling of arbitrary words   \n",
       "2  Leveraging content dimensions during the trans...   \n",
       "\n",
       "                                     patent_abstract  \\\n",
       "0  Designing a natural language understanding (NL...   \n",
       "1  Methods, systems, and apparatus, including com...   \n",
       "2  A content management system (CMS) and a transl...   \n",
       "\n",
       "  patent_firstnamed_assignee_id patent_year patent_type patent_kind  \\\n",
       "0      org_ID497r4tFbCIaMBjGAST        2019     utility          B2   \n",
       "1      org_p6ofWD2xFNSnyYkj6wpA        2019     utility          B1   \n",
       "2      org_Vbc6obpnxWM42d0HjlXY        2019     utility          B1   \n",
       "\n",
       "                               patent_title_abstract  \n",
       "0  Initializing a workspace for building a natura...  \n",
       "1  Allowing spelling of arbitrary words Methods, ...  \n",
       "2  Leveraging content dimensions during the trans...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_20pats.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patent_number</th>\n",
       "      <th>patent_date</th>\n",
       "      <th>patent_title</th>\n",
       "      <th>patent_abstract</th>\n",
       "      <th>patent_firstnamed_assignee_id</th>\n",
       "      <th>patent_year</th>\n",
       "      <th>patent_type</th>\n",
       "      <th>patent_kind</th>\n",
       "      <th>patent_title_abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10229106</td>\n",
       "      <td>2019-03-12</td>\n",
       "      <td>Initializing a workspace for building a natura...</td>\n",
       "      <td>Designing a natural language understanding (NL...</td>\n",
       "      <td>org_ID497r4tFbCIaMBjGAST</td>\n",
       "      <td>2019</td>\n",
       "      <td>utility</td>\n",
       "      <td>B2</td>\n",
       "      <td>Initializing a workspace for building a natura...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10229109</td>\n",
       "      <td>2019-03-12</td>\n",
       "      <td>Allowing spelling of arbitrary words</td>\n",
       "      <td>Methods, systems, and apparatus, including com...</td>\n",
       "      <td>org_p6ofWD2xFNSnyYkj6wpA</td>\n",
       "      <td>2019</td>\n",
       "      <td>utility</td>\n",
       "      <td>B1</td>\n",
       "      <td>Allowing spelling of arbitrary words Methods, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10229113</td>\n",
       "      <td>2019-03-12</td>\n",
       "      <td>Leveraging content dimensions during the trans...</td>\n",
       "      <td>A content management system (CMS) and a transl...</td>\n",
       "      <td>org_Vbc6obpnxWM42d0HjlXY</td>\n",
       "      <td>2019</td>\n",
       "      <td>utility</td>\n",
       "      <td>B1</td>\n",
       "      <td>Leveraging content dimensions during the trans...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  patent_number patent_date  \\\n",
       "0      10229106  2019-03-12   \n",
       "1      10229109  2019-03-12   \n",
       "2      10229113  2019-03-12   \n",
       "\n",
       "                                        patent_title  \\\n",
       "0  Initializing a workspace for building a natura...   \n",
       "1               Allowing spelling of arbitrary words   \n",
       "2  Leveraging content dimensions during the trans...   \n",
       "\n",
       "                                     patent_abstract  \\\n",
       "0  Designing a natural language understanding (NL...   \n",
       "1  Methods, systems, and apparatus, including com...   \n",
       "2  A content management system (CMS) and a transl...   \n",
       "\n",
       "  patent_firstnamed_assignee_id patent_year patent_type patent_kind  \\\n",
       "0      org_ID497r4tFbCIaMBjGAST        2019     utility          B2   \n",
       "1      org_p6ofWD2xFNSnyYkj6wpA        2019     utility          B1   \n",
       "2      org_Vbc6obpnxWM42d0HjlXY        2019     utility          B1   \n",
       "\n",
       "                               patent_title_abstract  \n",
       "0  Initializing a workspace for building a natura...  \n",
       "1  Allowing spelling of arbitrary words Methods, ...  \n",
       "2  Leveraging content dimensions during the trans...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_20pats.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# see error message\n",
    "df_20pats.sort_values(by=['patent_date'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Partition data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patent_number</th>\n",
       "      <th>patent_date</th>\n",
       "      <th>patent_title</th>\n",
       "      <th>patent_abstract</th>\n",
       "      <th>patent_firstnamed_assignee_id</th>\n",
       "      <th>patent_year</th>\n",
       "      <th>patent_type</th>\n",
       "      <th>patent_kind</th>\n",
       "      <th>patent_title_abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2479</th>\n",
       "      <td>4502128</td>\n",
       "      <td>1985-02-26</td>\n",
       "      <td>Translation between natural languages</td>\n",
       "      <td>An input sentence described by a first natural...</td>\n",
       "      <td>org_70D1lR89kQnFiCFdJ6s5</td>\n",
       "      <td>1985</td>\n",
       "      <td>utility</td>\n",
       "      <td>A</td>\n",
       "      <td>Translation between natural languages An input...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2477</th>\n",
       "      <td>4599612</td>\n",
       "      <td>1986-07-08</td>\n",
       "      <td>Displaying and correcting method for machine t...</td>\n",
       "      <td>In a system wherein a first text in a first na...</td>\n",
       "      <td>org_70D1lR89kQnFiCFdJ6s5</td>\n",
       "      <td>1986</td>\n",
       "      <td>utility</td>\n",
       "      <td>A</td>\n",
       "      <td>Displaying and correcting method for machine t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2475</th>\n",
       "      <td>4661924</td>\n",
       "      <td>1987-04-28</td>\n",
       "      <td>Multiple-parts-of-speech disambiguating method...</td>\n",
       "      <td>A machine translation system comprises input m...</td>\n",
       "      <td>org_70D1lR89kQnFiCFdJ6s5</td>\n",
       "      <td>1987</td>\n",
       "      <td>utility</td>\n",
       "      <td>A</td>\n",
       "      <td>Multiple-parts-of-speech disambiguating method...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2471</th>\n",
       "      <td>4736296</td>\n",
       "      <td>1988-04-05</td>\n",
       "      <td>Method and apparatus of intelligent guidance i...</td>\n",
       "      <td>A method and apparatus of intelligent guidance...</td>\n",
       "      <td>org_70D1lR89kQnFiCFdJ6s5</td>\n",
       "      <td>1988</td>\n",
       "      <td>utility</td>\n",
       "      <td>A</td>\n",
       "      <td>Method and apparatus of intelligent guidance i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2466</th>\n",
       "      <td>4887212</td>\n",
       "      <td>1989-12-12</td>\n",
       "      <td>Parser for natural language text</td>\n",
       "      <td>An improved natural language text parser is di...</td>\n",
       "      <td>org_q9Bn28RHhpYrQjKvraAH</td>\n",
       "      <td>1989</td>\n",
       "      <td>utility</td>\n",
       "      <td>A</td>\n",
       "      <td>Parser for natural language text An improved n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     patent_number patent_date  \\\n",
       "2479       4502128  1985-02-26   \n",
       "2477       4599612  1986-07-08   \n",
       "2475       4661924  1987-04-28   \n",
       "2471       4736296  1988-04-05   \n",
       "2466       4887212  1989-12-12   \n",
       "\n",
       "                                           patent_title  \\\n",
       "2479              Translation between natural languages   \n",
       "2477  Displaying and correcting method for machine t...   \n",
       "2475  Multiple-parts-of-speech disambiguating method...   \n",
       "2471  Method and apparatus of intelligent guidance i...   \n",
       "2466                   Parser for natural language text   \n",
       "\n",
       "                                        patent_abstract  \\\n",
       "2479  An input sentence described by a first natural...   \n",
       "2477  In a system wherein a first text in a first na...   \n",
       "2475  A machine translation system comprises input m...   \n",
       "2471  A method and apparatus of intelligent guidance...   \n",
       "2466  An improved natural language text parser is di...   \n",
       "\n",
       "     patent_firstnamed_assignee_id patent_year patent_type patent_kind  \\\n",
       "2479      org_70D1lR89kQnFiCFdJ6s5        1985     utility           A   \n",
       "2477      org_70D1lR89kQnFiCFdJ6s5        1986     utility           A   \n",
       "2475      org_70D1lR89kQnFiCFdJ6s5        1987     utility           A   \n",
       "2471      org_70D1lR89kQnFiCFdJ6s5        1988     utility           A   \n",
       "2466      org_q9Bn28RHhpYrQjKvraAH        1989     utility           A   \n",
       "\n",
       "                                  patent_title_abstract  \n",
       "2479  Translation between natural languages An input...  \n",
       "2477  Displaying and correcting method for machine t...  \n",
       "2475  Multiple-parts-of-speech disambiguating method...  \n",
       "2471  Method and apparatus of intelligent guidance i...  \n",
       "2466  Parser for natural language text An improved n...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_20pats[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "894"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_20pats = df_20pats[:894]\n",
    "len(train_20pats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patent_number</th>\n",
       "      <th>patent_date</th>\n",
       "      <th>patent_title</th>\n",
       "      <th>patent_abstract</th>\n",
       "      <th>patent_firstnamed_assignee_id</th>\n",
       "      <th>patent_year</th>\n",
       "      <th>patent_type</th>\n",
       "      <th>patent_kind</th>\n",
       "      <th>patent_title_abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2479</th>\n",
       "      <td>4502128</td>\n",
       "      <td>1985-02-26</td>\n",
       "      <td>Translation between natural languages</td>\n",
       "      <td>An input sentence described by a first natural...</td>\n",
       "      <td>org_70D1lR89kQnFiCFdJ6s5</td>\n",
       "      <td>1985</td>\n",
       "      <td>utility</td>\n",
       "      <td>A</td>\n",
       "      <td>Translation between natural languages An input...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2477</th>\n",
       "      <td>4599612</td>\n",
       "      <td>1986-07-08</td>\n",
       "      <td>Displaying and correcting method for machine t...</td>\n",
       "      <td>In a system wherein a first text in a first na...</td>\n",
       "      <td>org_70D1lR89kQnFiCFdJ6s5</td>\n",
       "      <td>1986</td>\n",
       "      <td>utility</td>\n",
       "      <td>A</td>\n",
       "      <td>Displaying and correcting method for machine t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2475</th>\n",
       "      <td>4661924</td>\n",
       "      <td>1987-04-28</td>\n",
       "      <td>Multiple-parts-of-speech disambiguating method...</td>\n",
       "      <td>A machine translation system comprises input m...</td>\n",
       "      <td>org_70D1lR89kQnFiCFdJ6s5</td>\n",
       "      <td>1987</td>\n",
       "      <td>utility</td>\n",
       "      <td>A</td>\n",
       "      <td>Multiple-parts-of-speech disambiguating method...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2471</th>\n",
       "      <td>4736296</td>\n",
       "      <td>1988-04-05</td>\n",
       "      <td>Method and apparatus of intelligent guidance i...</td>\n",
       "      <td>A method and apparatus of intelligent guidance...</td>\n",
       "      <td>org_70D1lR89kQnFiCFdJ6s5</td>\n",
       "      <td>1988</td>\n",
       "      <td>utility</td>\n",
       "      <td>A</td>\n",
       "      <td>Method and apparatus of intelligent guidance i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2466</th>\n",
       "      <td>4887212</td>\n",
       "      <td>1989-12-12</td>\n",
       "      <td>Parser for natural language text</td>\n",
       "      <td>An improved natural language text parser is di...</td>\n",
       "      <td>org_q9Bn28RHhpYrQjKvraAH</td>\n",
       "      <td>1989</td>\n",
       "      <td>utility</td>\n",
       "      <td>A</td>\n",
       "      <td>Parser for natural language text An improved n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     patent_number patent_date  \\\n",
       "2479       4502128  1985-02-26   \n",
       "2477       4599612  1986-07-08   \n",
       "2475       4661924  1987-04-28   \n",
       "2471       4736296  1988-04-05   \n",
       "2466       4887212  1989-12-12   \n",
       "\n",
       "                                           patent_title  \\\n",
       "2479              Translation between natural languages   \n",
       "2477  Displaying and correcting method for machine t...   \n",
       "2475  Multiple-parts-of-speech disambiguating method...   \n",
       "2471  Method and apparatus of intelligent guidance i...   \n",
       "2466                   Parser for natural language text   \n",
       "\n",
       "                                        patent_abstract  \\\n",
       "2479  An input sentence described by a first natural...   \n",
       "2477  In a system wherein a first text in a first na...   \n",
       "2475  A machine translation system comprises input m...   \n",
       "2471  A method and apparatus of intelligent guidance...   \n",
       "2466  An improved natural language text parser is di...   \n",
       "\n",
       "     patent_firstnamed_assignee_id patent_year patent_type patent_kind  \\\n",
       "2479      org_70D1lR89kQnFiCFdJ6s5        1985     utility           A   \n",
       "2477      org_70D1lR89kQnFiCFdJ6s5        1986     utility           A   \n",
       "2475      org_70D1lR89kQnFiCFdJ6s5        1987     utility           A   \n",
       "2471      org_70D1lR89kQnFiCFdJ6s5        1988     utility           A   \n",
       "2466      org_q9Bn28RHhpYrQjKvraAH        1989     utility           A   \n",
       "\n",
       "                                  patent_title_abstract  \n",
       "2479  Translation between natural languages An input...  \n",
       "2477  Displaying and correcting method for machine t...  \n",
       "2475  Multiple-parts-of-speech disambiguating method...  \n",
       "2471  Method and apparatus of intelligent guidance i...  \n",
       "2466  Parser for natural language text An improved n...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_20pats[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_20pats = df_20pats[894:]\n",
    "len(test_20pats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1118.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO (Lee) - find better way to partition based on dates by percentage\n",
    "1118 * .8\n",
    "\n",
    "1118 *.2\n",
    "\n",
    "1118 * .8 + 1118 *.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore nested datasets - assignees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_assignees = json_normalize(results['patents'], record_path=['assignees'], meta=['patent_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assignee_city</th>\n",
       "      <th>assignee_country</th>\n",
       "      <th>assignee_county</th>\n",
       "      <th>assignee_county_fips</th>\n",
       "      <th>assignee_first_name</th>\n",
       "      <th>assignee_first_seen_date</th>\n",
       "      <th>assignee_id</th>\n",
       "      <th>assignee_key_id</th>\n",
       "      <th>assignee_last_name</th>\n",
       "      <th>assignee_last_seen_date</th>\n",
       "      <th>assignee_lastknown_city</th>\n",
       "      <th>assignee_lastknown_country</th>\n",
       "      <th>assignee_lastknown_latitude</th>\n",
       "      <th>assignee_lastknown_location_id</th>\n",
       "      <th>assignee_lastknown_longitude</th>\n",
       "      <th>assignee_lastknown_state</th>\n",
       "      <th>assignee_latitude</th>\n",
       "      <th>assignee_location_id</th>\n",
       "      <th>assignee_longitude</th>\n",
       "      <th>assignee_organization</th>\n",
       "      <th>assignee_sequence</th>\n",
       "      <th>assignee_state</th>\n",
       "      <th>assignee_state_fips</th>\n",
       "      <th>assignee_total_num_inventors</th>\n",
       "      <th>assignee_total_num_patents</th>\n",
       "      <th>assignee_type</th>\n",
       "      <th>patent_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1911</th>\n",
       "      <td>Tokyo</td>\n",
       "      <td>JP</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>2007-10-16</td>\n",
       "      <td>org_SEywROQVbKV7Zj6CtfEE</td>\n",
       "      <td>344976</td>\n",
       "      <td>None</td>\n",
       "      <td>2007-10-16</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>JP</td>\n",
       "      <td>35.685</td>\n",
       "      <td>35.685|139.7514</td>\n",
       "      <td>139.751</td>\n",
       "      <td>None</td>\n",
       "      <td>35.685</td>\n",
       "      <td>35.685|139.7514</td>\n",
       "      <td>139.751</td>\n",
       "      <td>Fuji Xexox Co., Ltd.</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7283958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     assignee_city assignee_country assignee_county assignee_county_fips  \\\n",
       "1911         Tokyo               JP            None                    0   \n",
       "\n",
       "     assignee_first_name assignee_first_seen_date               assignee_id  \\\n",
       "1911                None               2007-10-16  org_SEywROQVbKV7Zj6CtfEE   \n",
       "\n",
       "     assignee_key_id assignee_last_name assignee_last_seen_date  \\\n",
       "1911          344976               None              2007-10-16   \n",
       "\n",
       "     assignee_lastknown_city assignee_lastknown_country  \\\n",
       "1911                   Tokyo                         JP   \n",
       "\n",
       "     assignee_lastknown_latitude assignee_lastknown_location_id  \\\n",
       "1911                      35.685                35.685|139.7514   \n",
       "\n",
       "     assignee_lastknown_longitude assignee_lastknown_state assignee_latitude  \\\n",
       "1911                      139.751                     None            35.685   \n",
       "\n",
       "     assignee_location_id assignee_longitude assignee_organization  \\\n",
       "1911      35.685|139.7514            139.751  Fuji Xexox Co., Ltd.   \n",
       "\n",
       "     assignee_sequence assignee_state assignee_state_fips  \\\n",
       "1911                 0           None                   0   \n",
       "\n",
       "     assignee_total_num_inventors assignee_total_num_patents assignee_type  \\\n",
       "1911                            4                          1             3   \n",
       "\n",
       "     patent_number  \n",
       "1911       7283958  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_assignees[df_assignees['assignee_id'] == \"org_SEywROQVbKV7Zj6CtfEE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assignee_city</th>\n",
       "      <th>assignee_country</th>\n",
       "      <th>assignee_county</th>\n",
       "      <th>assignee_county_fips</th>\n",
       "      <th>assignee_first_name</th>\n",
       "      <th>assignee_first_seen_date</th>\n",
       "      <th>assignee_id</th>\n",
       "      <th>assignee_key_id</th>\n",
       "      <th>assignee_last_name</th>\n",
       "      <th>assignee_last_seen_date</th>\n",
       "      <th>assignee_lastknown_city</th>\n",
       "      <th>assignee_lastknown_country</th>\n",
       "      <th>assignee_lastknown_latitude</th>\n",
       "      <th>assignee_lastknown_location_id</th>\n",
       "      <th>assignee_lastknown_longitude</th>\n",
       "      <th>assignee_lastknown_state</th>\n",
       "      <th>assignee_latitude</th>\n",
       "      <th>assignee_location_id</th>\n",
       "      <th>assignee_longitude</th>\n",
       "      <th>assignee_organization</th>\n",
       "      <th>assignee_sequence</th>\n",
       "      <th>assignee_state</th>\n",
       "      <th>assignee_state_fips</th>\n",
       "      <th>assignee_total_num_inventors</th>\n",
       "      <th>assignee_total_num_patents</th>\n",
       "      <th>assignee_type</th>\n",
       "      <th>patent_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Beijing</td>\n",
       "      <td>CN</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>1990-04-17</td>\n",
       "      <td>org_myRnscKfY7JOy5h8LVrg</td>\n",
       "      <td>267177</td>\n",
       "      <td>None</td>\n",
       "      <td>2019-02-19</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>CN</td>\n",
       "      <td>39.9042</td>\n",
       "      <td>39.9042|116.4074</td>\n",
       "      <td>116.407</td>\n",
       "      <td>None</td>\n",
       "      <td>39.9042</td>\n",
       "      <td>39.9042|116.4074</td>\n",
       "      <td>116.407</td>\n",
       "      <td>Peking University</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>463</td>\n",
       "      <td>224</td>\n",
       "      <td>3</td>\n",
       "      <td>10210245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Shenzhen</td>\n",
       "      <td>CN</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>2009-06-23</td>\n",
       "      <td>org_O0GfNE8msswIVOwTLezZ</td>\n",
       "      <td>282280</td>\n",
       "      <td>None</td>\n",
       "      <td>2019-03-12</td>\n",
       "      <td>Shenzhen</td>\n",
       "      <td>CN</td>\n",
       "      <td>22.5333</td>\n",
       "      <td>22.5333|114.1333</td>\n",
       "      <td>114.133</td>\n",
       "      <td>None</td>\n",
       "      <td>22.5333</td>\n",
       "      <td>22.5333|114.1333</td>\n",
       "      <td>114.133</td>\n",
       "      <td>TENCENT TECHNOLOGY (SHENZHEN) COMPANY LIMITED</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1977</td>\n",
       "      <td>1421</td>\n",
       "      <td>3</td>\n",
       "      <td>10210245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   assignee_city assignee_country assignee_county assignee_county_fips  \\\n",
       "36       Beijing               CN            None                    0   \n",
       "37      Shenzhen               CN            None                    0   \n",
       "\n",
       "   assignee_first_name assignee_first_seen_date               assignee_id  \\\n",
       "36                None               1990-04-17  org_myRnscKfY7JOy5h8LVrg   \n",
       "37                None               2009-06-23  org_O0GfNE8msswIVOwTLezZ   \n",
       "\n",
       "   assignee_key_id assignee_last_name assignee_last_seen_date  \\\n",
       "36          267177               None              2019-02-19   \n",
       "37          282280               None              2019-03-12   \n",
       "\n",
       "   assignee_lastknown_city assignee_lastknown_country  \\\n",
       "36                 Beijing                         CN   \n",
       "37                Shenzhen                         CN   \n",
       "\n",
       "   assignee_lastknown_latitude assignee_lastknown_location_id  \\\n",
       "36                     39.9042               39.9042|116.4074   \n",
       "37                     22.5333               22.5333|114.1333   \n",
       "\n",
       "   assignee_lastknown_longitude assignee_lastknown_state assignee_latitude  \\\n",
       "36                      116.407                     None           39.9042   \n",
       "37                      114.133                     None           22.5333   \n",
       "\n",
       "   assignee_location_id assignee_longitude  \\\n",
       "36     39.9042|116.4074            116.407   \n",
       "37     22.5333|114.1333            114.133   \n",
       "\n",
       "                            assignee_organization assignee_sequence  \\\n",
       "36                              Peking University                 0   \n",
       "37  TENCENT TECHNOLOGY (SHENZHEN) COMPANY LIMITED                 1   \n",
       "\n",
       "   assignee_state assignee_state_fips assignee_total_num_inventors  \\\n",
       "36           None                   0                          463   \n",
       "37           None                   0                         1977   \n",
       "\n",
       "   assignee_total_num_patents assignee_type patent_number  \n",
       "36                        224             3      10210245  \n",
       "37                       1421             3      10210245  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_assignees[df_assignees['patent_number'] == \"10210245\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patent_number</th>\n",
       "      <th>patent_date</th>\n",
       "      <th>patent_title</th>\n",
       "      <th>patent_abstract</th>\n",
       "      <th>patent_firstnamed_assignee_id</th>\n",
       "      <th>patent_year</th>\n",
       "      <th>patent_type</th>\n",
       "      <th>patent_kind</th>\n",
       "      <th>patent_title_abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>10210245</td>\n",
       "      <td>2019-02-19</td>\n",
       "      <td>Natural language question answering method and...</td>\n",
       "      <td>A natural language question answering method a...</td>\n",
       "      <td>org_myRnscKfY7JOy5h8LVrg</td>\n",
       "      <td>2019</td>\n",
       "      <td>utility</td>\n",
       "      <td>B2</td>\n",
       "      <td>Natural language question answering method and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patent_number patent_date  \\\n",
       "36      10210245  2019-02-19   \n",
       "\n",
       "                                         patent_title  \\\n",
       "36  Natural language question answering method and...   \n",
       "\n",
       "                                      patent_abstract  \\\n",
       "36  A natural language question answering method a...   \n",
       "\n",
       "   patent_firstnamed_assignee_id patent_year patent_type patent_kind  \\\n",
       "36      org_myRnscKfY7JOy5h8LVrg        2019     utility          B2   \n",
       "\n",
       "                                patent_title_abstract  \n",
       "36  Natural language question answering method and...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['patent_number'] == \"10210245\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other nested tables for investigation - uncomment to use\n",
    "\n",
    "# json_normalize(results['patents'][0], record_path='applications')\n",
    "\n",
    "# inspect nested datasets, column by column\n",
    "\n",
    "# json_normalize(results['patents'][0])\n",
    "# json_normalize(results['patents'][0], record_path='IPCs')\n",
    "# json_normalize(results['patents'][0], record_path='application_citations')\n",
    "# json_normalize(results['patents'][0], record_path='applications')\n",
    "# json_normalize(results['patents'][2], record_path='assignees')\n",
    "# json_normalize(results['patents'][0], record_path='cited_patents')\n",
    "# json_normalize(results['patents'][0], record_path='citedby_patents')\n",
    "# json_normalize(results['patents'][24], record_path='cpcs')\n",
    "# json_normalize(results['patents'][0], record_path='examiners')\n",
    "# json_normalize(results['patents'][0], record_path='foreign_priority')\n",
    "# json_normalize(results['patents'][0], record_path='gov_interests')\n",
    "# json_normalize(results['patents'][0], record_path='inventors')\n",
    "# json_normalize(results['patents'][0], record_path='lawyers')\n",
    "# json_normalize(results['patents'][0], record_path='nbers')\n",
    "# json_normalize(results['patents'][0], record_path='pct_data')\n",
    "# json_normalize(results['patents'][0], record_path='rawinventors')\n",
    "# json_normalize(results['patents'][0:5], record_path='uspcs')\n",
    "# json_normalize(results['patents'][0], record_path='examiners')\n",
    "# json_normalize(results['patents'][0], record_path='wipos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map values of series according to input correspondence\n",
    "# substitute each value in series derived from NLTK word_tokenize function\n",
    "text_data = df['patent_title_abstract'].map(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Initializing, a, workspace, for, building, a,...\n",
       "1    [Allowing, spelling, of, arbitrary, words, Met...\n",
       "2    [Leveraging, content, dimensions, during, the,...\n",
       "Name: patent_title_abstract, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect the first 3 items in `data` to see how everything looks \n",
    "text_data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0621 09:41:41.776201 4563789248 smart_open_lib.py:379] this function is deprecated, use smart_open.open instead\n"
     ]
    }
   ],
   "source": [
    "# instantiate word2vec model\n",
    "# window: maximum distance between the current and predicted word within a sentence\n",
    "# size: number of dimensions for word vectors\n",
    "# min_count: min word frequency in vocab cutoff threshhold\n",
    "# workers param: number of worker threads to train model, for faster training with multicore machines\n",
    "model_w2v = Word2Vec(text_data, size=100, window=5, min_count=1, workers=4)\n",
    "model_w2v.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2482"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'corpus_count' returns number of sentences in dataset, in this case, 200K sentences\n",
    "model_w2v.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0621 09:41:48.238798 4563789248 base_any2vec.py:596] Effective 'alpha' higher than previous training cycles\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2425955, 3583700)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train updates the model’s neural weights from a sequence of sentences\n",
    "# training is streamed, meaning sentences can be a generator that reads input data from disk on-the-fly,\n",
    "# without loading the entire corpus into RAM. This also means you can continue training the model later:\n",
    "\n",
    "model_w2v.train(text_data, total_examples=model_w2v.corpus_count, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .wv separates trained word vectors in a KeyedVectors instance and assigns to var so don't need full model state\n",
    "# (don’t need to continue training) by discarding state, we have a much smaller and faster object that can be\n",
    "# mapped for fast loading and sharing the vectors in RAM between processes\n",
    "\n",
    "# uncomment to run\n",
    "# word_vectors = model_w2v.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2VecTrainables at 0x1a47b89048>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v.trainables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_words_list = ['computer', 'language', 'user']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"'s\", 0.05287172),\n",
       " ('program', 0.037009317),\n",
       " ('interface', 0.03312036),\n",
       " ('readable', 0.009747167),\n",
       " ('A', 0.0062622274),\n",
       " ('implemented', 0.00519008),\n",
       " ('resource', 0.0037051453),\n",
       " ('Natural', 0.003327496),\n",
       " ('running', 0.0031767657),\n",
       " ('instructions', 0.0030982874)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gets the probability distribution of the center word given context words\n",
    "model_w2v.predict_output_word(context_words_list, topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_vectors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-39fad8d4542b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# compute cosine similarity & return most similar words to a word passed to function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mword_vectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'generation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'word_vectors' is not defined"
     ]
    }
   ],
   "source": [
    "# compute cosine similarity & return most similar words to a word passed to function\n",
    "word_vectors.most_similar(positive='generation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9476, 100)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get word vector for a given word\n",
    "word_vectors['generate']\n",
    "\n",
    "# returns word vectors for entire vocabulary(dictionary)\n",
    "word_vectors.vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features\n",
    "data = train_20pats['patent_title_abstract'].map(word_tokenize).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Translation',\n",
       " 'between',\n",
       " 'natural',\n",
       " 'languages',\n",
       " 'An',\n",
       " 'input',\n",
       " 'sentence',\n",
       " 'described',\n",
       " 'by',\n",
       " 'a']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target\n",
    "target_train = train_20pats.patent_firstnamed_assignee_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2479    org_70D1lR89kQnFiCFdJ6s5\n",
       "2477    org_70D1lR89kQnFiCFdJ6s5\n",
       "2475    org_70D1lR89kQnFiCFdJ6s5\n",
       "Name: patent_firstnamed_assignee_id, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download zip file of GloVe model pretrained weights from Stanford NLP\n",
    "# !wget http://nlp.stanford.edu/data/glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # calculate total vocab of our dataset by adding every word in the dataset into a python set object. \n",
    "vocab = set(word for doc in data for word in doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5279"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # number of tokens in this dataset\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code\n",
    "glove = {}\n",
    "with open('data/glove.6B.50d.txt', 'rb') as f:\n",
    "    for line in f:\n",
    "        parts = line.split()\n",
    "        word = parts[0].decode('utf-8')\n",
    "        if word in vocab:\n",
    "            vector = np.array(parts[1:], dtype=np.float32)\n",
    "            glove[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.94418 ,  0.099466,  1.5637  ,  0.19514 , -0.18374 ,  0.21001 ,\n",
       "        0.41893 , -0.4262  ,  0.45778 ,  1.3884  , -0.15093 , -0.11383 ,\n",
       "        0.77912 , -0.47679 ,  0.11494 ,  0.19519 ,  0.75934 ,  0.51346 ,\n",
       "       -0.26984 , -1.2975  ,  0.90748 , -1.1802  ,  0.17354 , -0.53419 ,\n",
       "        0.57519 , -0.21494 , -0.11276 , -0.43246 ,  0.73511 ,  0.10268 ,\n",
       "        2.8403  ,  0.68922 ,  0.075201, -0.7718  , -0.51294 ,  0.081105,\n",
       "       -0.39304 , -0.049972,  0.1209  , -0.33339 ,  0.28529 , -0.16663 ,\n",
       "       -0.30613 ,  0.44213 , -0.51871 ,  0.15192 ,  0.36517 ,  0.86671 ,\n",
       "       -0.24538 ,  0.15246 ], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove['generate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # code\n",
    "# class W2vVectorizer(object):\n",
    "    \n",
    "#     def __init__(self, w2v):\n",
    "#         # takes in a dictionary of words and vectors as input\n",
    "#         self.w2v = w2v\n",
    "#         if len(w2v) == 0:\n",
    "#             self.dimensions = 0\n",
    "#         else:\n",
    "#             self.dimensions = len(w2v[next(iter(glove))])\n",
    "    \n",
    "#     # Note from Mike: Even though it doesn't do anything, it's required that this object implement a fit method or else\n",
    "#     # It can't be used in a sklearn Pipeline. \n",
    "#     def fit(self, X, y):\n",
    "#         return self\n",
    "            \n",
    "#     def transform(self, X):\n",
    "#         return np.array([\n",
    "#             np.mean([self.w2v[w] for w in words if w in self.w2v]\n",
    "#                    or [np.zeros(self.dimensions)], axis=0) for words in X])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text classification with neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-process features data\n",
    "\n",
    "# tokenize features\n",
    "# data = train_20pats['patent_title_abstract'].map(word_tokenize).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO (Lee) - find alternate way to do this with tf?\n",
    "y_train_20pats = pd.get_dummies(target_train).values\n",
    "\n",
    "y_train_20pats[0]\n",
    "\n",
    "# uncomment to continue trying with tf.one_hot\n",
    "# tf.one_hot(target_train, depth=13, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate tf tokenizer\n",
    "tokenizer = text.Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(894, 277)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train set features - pre-processing\n",
    "# train set - tokenize, lower, clean punctuation in train set\n",
    "tokenizer.fit_on_texts(list(train_20pats.patent_title_abstract))\n",
    "\n",
    "# train set - transform each word(token?) in document to sequence of integers that index word strings\n",
    "tokenized_docs = tokenizer.texts_to_sequences(train_20pats.patent_title_abstract)\n",
    "\n",
    "# train set - pad sequences to max length of title and abstract\n",
    "X_train_20pats = sequence.pad_sequences(tokenized_docs)\n",
    "\n",
    "# train set - inspect shape\n",
    "X_train_20pats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 296)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO (Lee) - resolve process to pre-process steps of word tokenization etc. on test data\n",
    "# test set features - pre-processing\n",
    "\n",
    "# test set - tokenize, lower, clean punctuation\n",
    "tokenizer.fit_on_texts(list(test_20pats.patent_title_abstract))\n",
    "\n",
    "# test set - transform each word(token?) in document to sequence of integers that index word strings\n",
    "tokenized_docs_test = tokenizer.texts_to_sequences(test_20pats.patent_title_abstract)\n",
    "\n",
    "# test set - pad sequences to max length of title and abstract\n",
    "X_test_20pats = sequence.pad_sequences(tokenized_docs_test)\n",
    "\n",
    "# test set - inspect shape\n",
    "X_test_20pats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pre-process test labels\n",
    "target_test = test_20pats.patent_firstnamed_assignee_id\n",
    "\n",
    "# TODO (Lee) - find alternate way to do this with tf?\n",
    "y_test_20pats = pd.get_dummies(target_test).values\n",
    "\n",
    "y_test_20pats[0]\n",
    "\n",
    "# uncomment to continue trying with tf.one_hot\n",
    "# tf.one_hot(target_train, depth=13, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LSTMs\n",
    "- learn what is important to remember by constantly updating their internal state\n",
    "- similar to GRUs (gated recurrent units)\n",
    "- comprise 3 gates:\n",
    "    - input gate, which determines how much of the cell state that was passed along should be kept\n",
    "    - forget gate, which determines how much of the current state should be forgotten\n",
    "    - output gate, which determines how much of the current state should be exposed to the next layers in the network\n",
    "- learn patterns from sequences, even when sequences are long and extremely complex\n",
    "\n",
    "https://github.com/glmack/dsc-04-46-04-LSTMs-and-GRUs-seattle-ds-career-040119.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.model.Model groups layers into an object with training and inference features\n",
    "# instantiate Model in \"functional API\" approach by starting from Input, chaining layer calls for \n",
    "# forward pass, and then creating model from inputs and outputs\n",
    "\n",
    "# input layer - # TODO (Lee) - shape?\n",
    "inputs = Input(shape=(277,))\n",
    "\n",
    "# chain layer calls to specify model's forward pass\n",
    "\n",
    "# inputs = tf.keras.Input(shape=(3,))\n",
    "# x = tf.keras.layers.Dense(4, activation=tf.nn.relu)(inputs)\n",
    "# outputs = tf.keras.layers.Dense(5, activation=tf.nn.softmax)(x)\n",
    "\n",
    "# construct embedding layer to convert positive integers (indexes) into dense vectors of fixed size\n",
    "    # arg input_dim=5280 specifies size of vocab (maximum integer index) + 1\n",
    "    # arg output_dim=100 specifies dimension of dense embedding\n",
    "    # TODO (Lee) - describe (input_)\n",
    "# TODO (Lee) - reset to 277 dimensionality after error - test\n",
    "x = Embedding(5280, 100)(inputs)\n",
    "\n",
    "# construct LSTM layer (tf.keras.layers.LSTM) based on Long Short-Term Memory paper from Hochreiter 1997\n",
    "# arg units=25 specifies dimensionality of output space\n",
    "x = LSTM(25, return_sequences=True)(x)\n",
    "\n",
    "# construct global max pooling operation for temporal data\n",
    "x = GlobalMaxPool1D()(x)\n",
    "\n",
    "# construct dropout layer to help prevent overfitting by randomly setting fraction rate\n",
    "# of input units to 0 at each update during training time\n",
    "# arg rate=0.5 specifies fraction of input units to drop\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# construct dense layer, a regular densely-connected NN layer, that implements the operation:\n",
    "# output = activation(dot(input, kernel) + bias) where:\n",
    "    # activation is element-wise activation function passed as activation argument,\n",
    "    # kernel is weights matrix created by layer, \n",
    "    # bias is bias vector created by layer (only applicable if use_bias is True)\n",
    "# arg activation=relu specifies rectified linear unit as activation function\n",
    "# arg units=50 specifies dimensionality of output space.\n",
    "x = Dense(50, activation='relu')(x)\n",
    "\n",
    "# construct dropout layer to help prevent overfitting by randomly setting fraction rate\n",
    "# of input units to 0 at each update during training time\n",
    "# arg rate=0.5 specifies fraction of input units to drop\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# construct output layer as a dense layer with softmax activation function\n",
    "# specify arg units of 13, the dimensionality of output space for 13 classes\n",
    "# specify'softmax' activation function to output vector of predicted probability that example is class\n",
    "outputs = Dense(13, activation='softmax')(x)\n",
    "\n",
    "# create model from inputs and outputs\n",
    "model = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_size = 128\n",
    "# input_ = Input(shape=(100,))\n",
    "# x = Embedding(20000, embedding_size)(input_)\n",
    "# x = LSTM(25, return_sequences=True)(x)\n",
    "# x = GlobalMaxPool1D()(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "# x = Dense(50, activation='relu')(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "# # There are 41 different possible classes, so we use 41 neurons in our output layer\n",
    "# x = Dense(41, activation='softmax')(x)\n",
    "\n",
    "# model = Model(inputs=input_, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 277)]             0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 277, 100)          528000    \n",
      "_________________________________________________________________\n",
      "unified_lstm (UnifiedLSTM)   (None, 277, 25)           12600     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 50)                1300      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 13)                663       \n",
      "=================================================================\n",
      "Total params: 542,563\n",
      "Trainable params: 542,563\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 715 samples, validate on 179 samples\n",
      "Epoch 1/20\n",
      "715/715 [==============================] - 3s 5ms/sample - loss: 1.5720 - accuracy: 0.5049 - val_loss: 2.0482 - val_accuracy: 0.3575\n",
      "Epoch 2/20\n",
      "715/715 [==============================] - 3s 5ms/sample - loss: 1.5314 - accuracy: 0.5175 - val_loss: 2.2842 - val_accuracy: 0.4581\n",
      "Epoch 3/20\n",
      "715/715 [==============================] - 3s 5ms/sample - loss: 1.5288 - accuracy: 0.5105 - val_loss: 2.0560 - val_accuracy: 0.4078\n",
      "Epoch 4/20\n",
      "715/715 [==============================] - 3s 5ms/sample - loss: 1.4874 - accuracy: 0.5203 - val_loss: 2.1312 - val_accuracy: 0.3184\n",
      "Epoch 5/20\n",
      "715/715 [==============================] - 3s 5ms/sample - loss: 1.4631 - accuracy: 0.5357 - val_loss: 2.1448 - val_accuracy: 0.3240\n",
      "Epoch 6/20\n",
      "715/715 [==============================] - 3s 5ms/sample - loss: 1.4313 - accuracy: 0.5399 - val_loss: 2.1133 - val_accuracy: 0.3464\n",
      "Epoch 7/20\n",
      "715/715 [==============================] - 3s 5ms/sample - loss: 1.4220 - accuracy: 0.5371 - val_loss: 2.1505 - val_accuracy: 0.4078\n",
      "Epoch 8/20\n",
      "715/715 [==============================] - 3s 5ms/sample - loss: 1.3886 - accuracy: 0.5357 - val_loss: 2.0709 - val_accuracy: 0.4078\n",
      "Epoch 9/20\n",
      "715/715 [==============================] - 3s 5ms/sample - loss: 1.3504 - accuracy: 0.5427 - val_loss: 2.0953 - val_accuracy: 0.3240\n",
      "Epoch 10/20\n",
      "715/715 [==============================] - 3s 5ms/sample - loss: 1.3057 - accuracy: 0.5497 - val_loss: 2.0817 - val_accuracy: 0.3743\n",
      "Epoch 11/20\n",
      "715/715 [==============================] - 3s 5ms/sample - loss: 1.2075 - accuracy: 0.5860 - val_loss: 2.2290 - val_accuracy: 0.4134\n",
      "Epoch 12/20\n",
      "715/715 [==============================] - 3s 5ms/sample - loss: 1.1668 - accuracy: 0.6070 - val_loss: 2.0807 - val_accuracy: 0.4302\n",
      "Epoch 13/20\n",
      "715/715 [==============================] - 3s 5ms/sample - loss: 1.1245 - accuracy: 0.6210 - val_loss: 2.1454 - val_accuracy: 0.3408\n",
      "Epoch 14/20\n",
      "715/715 [==============================] - 4s 5ms/sample - loss: 1.0643 - accuracy: 0.6336 - val_loss: 2.3554 - val_accuracy: 0.3352\n",
      "Epoch 15/20\n",
      "715/715 [==============================] - 4s 5ms/sample - loss: 1.1640 - accuracy: 0.6238 - val_loss: 2.1514 - val_accuracy: 0.3911\n",
      "Epoch 16/20\n",
      "715/715 [==============================] - 4s 5ms/sample - loss: 1.0784 - accuracy: 0.6252 - val_loss: 2.1090 - val_accuracy: 0.4469\n",
      "Epoch 17/20\n",
      "715/715 [==============================] - 3s 5ms/sample - loss: 0.9991 - accuracy: 0.6895 - val_loss: 2.2528 - val_accuracy: 0.3799\n",
      "Epoch 18/20\n",
      "715/715 [==============================] - 3s 5ms/sample - loss: 0.9633 - accuracy: 0.6811 - val_loss: 2.2614 - val_accuracy: 0.3799\n",
      "Epoch 19/20\n",
      "715/715 [==============================] - 3s 5ms/sample - loss: 0.9252 - accuracy: 0.6895 - val_loss: 2.4174 - val_accuracy: 0.3743\n",
      "Epoch 20/20\n",
      "715/715 [==============================] - 3s 5ms/sample - loss: 0.9096 - accuracy: 0.6909 - val_loss: 2.2293 - val_accuracy: 0.3966\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a4b8c65c0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_20pats, y_train_20pats, epochs=20, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 804 samples, validate on 90 samples\n",
      "Epoch 1/2\n",
      "804/804 [==============================] - 4s 5ms/sample - loss: 2.1450 - accuracy: 0.3520 - val_loss: 1.9155 - val_accuracy: 0.6000\n",
      "Epoch 2/2\n",
      "804/804 [==============================] - 4s 5ms/sample - loss: 2.1041 - accuracy: 0.3669 - val_loss: 1.8931 - val_accuracy: 0.6000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a3cc28f28>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_20pats, y_train_20pats, epochs=5, batch_size=32, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "After 1 epoch, our model does about as well as the shallow algorithms we tried above.\n",
    "However, our LSTM Network was able to achieve a validation accuracy of over 40% after only 3 epochs of training.\n",
    "It's likely that if we trained for more epochs or added in the rest of the data, our performance would improve \n",
    "even further (but our run time would get much, much longer).\n",
    "\n",
    "It's common to embedding layers in LSTM networks, \n",
    "because both are special tools most commonly used for text data. \n",
    "# embedding layer creates it's own vectors based on the language in the text data it trains on,\n",
    "and then passes that information on to the LSTM network one word at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (TODO) - Lee - resolve\n",
    "# remove all tokens that are not alphabetic\n",
    "for patent in data:\n",
    "    words = [w.lower() for w in document if w.isalpha()]\n",
    "\n",
    "\n",
    "words\n",
    "# note that there is word loss here, e.g. the word non-expert, which contains a hypothesis, appears excluded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build RNN model, v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create RNN model with tf.keras.Sequential\n",
    "# RNN processes sequence input by iterating through elements and passing outputs\n",
    "# from one timestep to their input, and then to the next\n",
    "    \n",
    "model = Sequential([\n",
    "    # embedding layer - stores one vector per word, converts sequences of word idxs to sequences of vectors\n",
    "    # -vectors are trainable\n",
    "    # this index-lookup is much more efficient than equivalent operation of passing a one-hot encoded vector \n",
    "    # through a tf.keras.layers.Dense layer\n",
    "    Embedding(5280, 277),\n",
    "    # bidirectional wrapper helps RNN learn long range dependencies by propagating input\n",
    "    # forward and backwards through RNN layer and then concatenating output \n",
    "    Bidirectional(LSTM(277)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-5eface73bd0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m history = model.fit(X_train_20pats, epochs=10,\n\u001b[0;32m----> 2\u001b[0;31m                     validation_data=X_test_20pats)\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m     \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    810\u001b[0m       val_x, val_y, val_sample_weights = self._unpack_validation_data(\n\u001b[1;32m    811\u001b[0m           validation_data)\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_20pats, epochs=10,\n",
    "                    validation_data=X_test_20pats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

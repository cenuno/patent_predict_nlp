{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patent Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding\n",
    "from tensorflow.keras.layers import Dropout, Activation, Bidirectional, GlobalMaxPool1D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from tensorflow.keras.preprocessing import text, sequence\n",
    "\n",
    "import spacy\n",
    "from gensim.models import Word2Vec\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "\n",
    "from pandas.io.json import json_normalize\n",
    "import pickle\n",
    "from collections import ChainMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Data from PatentsView API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct GET request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_colwidth', -1)\n",
    "pd.options.display.max_columns = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patents endpoint\n",
    "endpoint_url = 'http://www.patentsview.org/api/patents/query'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build list from file of possible fields that endpoint request will return\n",
    "df = pd.read_excel(\"patents_view_patents_fields.xlsx\")\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n",
    "pat_fields = df.api_field_name.values.tolist()\n",
    "len(pat_fields) # 184 possible fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass directly into browser\n",
    "# http://www.patentsview.org/api/patents/query?q={\"_text_any\":{\"patent_abstract\":\"natural langugage processing\"}}\n",
    "# patents = []\n",
    "\n",
    "query={\"_or\":[{\"_text_phrase\":{\"patent_title\":\"natural language\"}},{\"_text_phrase\":{\"patent_abstract\":\"natural language\"}}]}\n",
    "fields=pat_fields\n",
    "options={\"per_page\":2500}\n",
    "sort=[{\"patent_date\":\"desc\"}]\n",
    "\n",
    "params={'q': json.dumps(query),\n",
    "        'f': json.dumps(fields),\n",
    "        'o': json.dumps(options),\n",
    "        's': json.dumps(sort)}\n",
    "\n",
    "# options (works) = {\"page\":1, \"per_page\":10}\n",
    "\n",
    "# other queries - uncomment to run\n",
    "# query (works) ={\"_text_all\":{\"patent_abstract\":\"nlp\"}},{\"_text_all\":{\"patent_abstract\":\"natural language processing\"}}]}\n",
    "# 529 results: {\"_text_phrase\":{\"patent_abstract\":\"natural language processing\"}} \n",
    "# 858 results: {\"_text_all\":{\"patent_abstract\":\"natural language processing\"}} \n",
    "# 957 results: query={\"_or\":[{\"_text_all\":{\"patent_title\":\"natural language processing\"}},{\"_text_all\":{\"patent_abstract\":\"natural language processing\"}}]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect results from GET CALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# request and results\n",
    "resp = requests.get(endpoint_url, params=params)\n",
    "results = resp.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status code: 200 ; reason: OK\n",
      "total_patent_count: 2482 ; patents_per_page: 2482\n"
     ]
    }
   ],
   "source": [
    "# extract metadata from response\n",
    "print(\"status code:\", resp.status_code,';', \"reason:\", resp.reason)\n",
    "total_patent_count = results[\"total_patent_count\"]\n",
    "patents_per_page = results['count']\n",
    "print(\"total_patent_count:\",total_patent_count,';', \"patents_per_page:\", patents_per_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IPCs</th>\n",
       "      <th>application_citations</th>\n",
       "      <th>applications</th>\n",
       "      <th>assignees</th>\n",
       "      <th>cited_patents</th>\n",
       "      <th>citedby_patents</th>\n",
       "      <th>cpcs</th>\n",
       "      <th>detail_desc_length</th>\n",
       "      <th>examiners</th>\n",
       "      <th>foreign_priority</th>\n",
       "      <th>gov_interests</th>\n",
       "      <th>inventors</th>\n",
       "      <th>lawyers</th>\n",
       "      <th>nbers</th>\n",
       "      <th>patent_abstract</th>\n",
       "      <th>patent_average_processing_time</th>\n",
       "      <th>patent_date</th>\n",
       "      <th>patent_firstnamed_assignee_city</th>\n",
       "      <th>patent_firstnamed_assignee_country</th>\n",
       "      <th>patent_firstnamed_assignee_id</th>\n",
       "      <th>patent_firstnamed_assignee_latitude</th>\n",
       "      <th>patent_firstnamed_assignee_location_id</th>\n",
       "      <th>patent_firstnamed_assignee_longitude</th>\n",
       "      <th>patent_firstnamed_assignee_state</th>\n",
       "      <th>patent_firstnamed_inventor_city</th>\n",
       "      <th>patent_firstnamed_inventor_country</th>\n",
       "      <th>patent_firstnamed_inventor_id</th>\n",
       "      <th>patent_firstnamed_inventor_latitude</th>\n",
       "      <th>patent_firstnamed_inventor_location_id</th>\n",
       "      <th>patent_firstnamed_inventor_longitude</th>\n",
       "      <th>patent_firstnamed_inventor_state</th>\n",
       "      <th>patent_kind</th>\n",
       "      <th>patent_num_cited_by_us_patents</th>\n",
       "      <th>patent_num_claims</th>\n",
       "      <th>patent_num_combined_citations</th>\n",
       "      <th>patent_num_foreign_citations</th>\n",
       "      <th>patent_num_us_application_citations</th>\n",
       "      <th>patent_num_us_patent_citations</th>\n",
       "      <th>patent_number</th>\n",
       "      <th>patent_processing_time</th>\n",
       "      <th>patent_title</th>\n",
       "      <th>patent_type</th>\n",
       "      <th>patent_year</th>\n",
       "      <th>pct_data</th>\n",
       "      <th>rawinventors</th>\n",
       "      <th>uspcs</th>\n",
       "      <th>wipos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'ipc_action_date': '2019-03-12', 'ipc_class'...</td>\n",
       "      <td>[{'appcit_app_number': '2002/20020077823', 'ap...</td>\n",
       "      <td>[{'app_country': 'US', 'app_date': '2013-07-26...</td>\n",
       "      <td>[{'assignee_city': 'Burlington', 'assignee_cou...</td>\n",
       "      <td>[{'cited_patent_category': 'cited by examiner'...</td>\n",
       "      <td>[{'citedby_patent_category': None, 'citedby_pa...</td>\n",
       "      <td>[{'cpc_category': None, 'cpc_first_seen_date':...</td>\n",
       "      <td>11570</td>\n",
       "      <td>[{'examiner_first_name': 'Michael N', 'examine...</td>\n",
       "      <td>[{'forprior_country': None, 'forprior_date': N...</td>\n",
       "      <td>[{'govint_contract_award_number': None, 'govin...</td>\n",
       "      <td>[{'inventor_city': 'Newton', 'inventor_country...</td>\n",
       "      <td>[{'lawyer_first_name': None, 'lawyer_first_see...</td>\n",
       "      <td>[{'nber_category_id': None, 'nber_category_tit...</td>\n",
       "      <td>Designing a natural language understanding (NL...</td>\n",
       "      <td>None</td>\n",
       "      <td>2019-03-12</td>\n",
       "      <td>Burlington</td>\n",
       "      <td>US</td>\n",
       "      <td>org_ID497r4tFbCIaMBjGAST</td>\n",
       "      <td>42.5047</td>\n",
       "      <td>42.5047|-71.1961</td>\n",
       "      <td>-71.1961</td>\n",
       "      <td>MA</td>\n",
       "      <td>Newton</td>\n",
       "      <td>US</td>\n",
       "      <td>7788103-1</td>\n",
       "      <td>42.3369</td>\n",
       "      <td>42.3369|-71.2097</td>\n",
       "      <td>-71.2097</td>\n",
       "      <td>MA</td>\n",
       "      <td>B2</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>10229106</td>\n",
       "      <td>2055</td>\n",
       "      <td>Initializing a workspace for building a natura...</td>\n",
       "      <td>utility</td>\n",
       "      <td>2019</td>\n",
       "      <td>[{'pct_102_date': None, 'pct_371_date': None, ...</td>\n",
       "      <td>[{'rawinventor_first_name': 'Jeffrey N.', 'raw...</td>\n",
       "      <td>[{'uspc_first_seen_date': None, 'uspc_last_see...</td>\n",
       "      <td>[{'wipo_field_id': None, 'wipo_field_title': N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'ipc_action_date': '2019-03-12', 'ipc_class'...</td>\n",
       "      <td>[{'appcit_app_number': '2002/20020138265', 'ap...</td>\n",
       "      <td>[{'app_country': 'US', 'app_date': '2017-09-11...</td>\n",
       "      <td>[{'assignee_city': 'Mountain View', 'assignee_...</td>\n",
       "      <td>[{'cited_patent_category': 'cited by applicant...</td>\n",
       "      <td>[{'citedby_patent_category': None, 'citedby_pa...</td>\n",
       "      <td>[{'cpc_category': None, 'cpc_first_seen_date':...</td>\n",
       "      <td>28118</td>\n",
       "      <td>[{'examiner_first_name': 'Shreyans A', 'examin...</td>\n",
       "      <td>[{'forprior_country': None, 'forprior_date': N...</td>\n",
       "      <td>[{'govint_contract_award_number': None, 'govin...</td>\n",
       "      <td>[{'inventor_city': 'Adliswil', 'inventor_count...</td>\n",
       "      <td>[{'lawyer_first_name': None, 'lawyer_first_see...</td>\n",
       "      <td>[{'nber_category_id': None, 'nber_category_tit...</td>\n",
       "      <td>Methods, systems, and apparatus, including com...</td>\n",
       "      <td>None</td>\n",
       "      <td>2019-03-12</td>\n",
       "      <td>Mountain View</td>\n",
       "      <td>US</td>\n",
       "      <td>org_p6ofWD2xFNSnyYkj6wpA</td>\n",
       "      <td>37.3861</td>\n",
       "      <td>37.3861|-122.0828</td>\n",
       "      <td>-122.083</td>\n",
       "      <td>CA</td>\n",
       "      <td>Adliswil</td>\n",
       "      <td>CH</td>\n",
       "      <td>8352247-1</td>\n",
       "      <td>47.3119</td>\n",
       "      <td>47.3119|8.5287</td>\n",
       "      <td>8.5287</td>\n",
       "      <td>None</td>\n",
       "      <td>B1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>10229109</td>\n",
       "      <td>547</td>\n",
       "      <td>Allowing spelling of arbitrary words</td>\n",
       "      <td>utility</td>\n",
       "      <td>2019</td>\n",
       "      <td>[{'pct_102_date': None, 'pct_371_date': None, ...</td>\n",
       "      <td>[{'rawinventor_first_name': 'Evgeny A.', 'rawi...</td>\n",
       "      <td>[{'uspc_first_seen_date': None, 'uspc_last_see...</td>\n",
       "      <td>[{'wipo_field_id': None, 'wipo_field_title': N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'ipc_action_date': '2019-03-12', 'ipc_class'...</td>\n",
       "      <td>[{'appcit_app_number': '2001/20010029455', 'ap...</td>\n",
       "      <td>[{'app_country': 'US', 'app_date': '2016-09-28...</td>\n",
       "      <td>[{'assignee_city': 'Seattle', 'assignee_countr...</td>\n",
       "      <td>[{'cited_patent_category': 'cited by applicant...</td>\n",
       "      <td>[{'citedby_patent_category': None, 'citedby_pa...</td>\n",
       "      <td>[{'cpc_category': None, 'cpc_first_seen_date':...</td>\n",
       "      <td>119654</td>\n",
       "      <td>[{'examiner_first_name': 'Jialong', 'examiner_...</td>\n",
       "      <td>[{'forprior_country': None, 'forprior_date': N...</td>\n",
       "      <td>[{'govint_contract_award_number': None, 'govin...</td>\n",
       "      <td>[{'inventor_city': 'Seattle', 'inventor_countr...</td>\n",
       "      <td>[{'lawyer_first_name': None, 'lawyer_first_see...</td>\n",
       "      <td>[{'nber_category_id': None, 'nber_category_tit...</td>\n",
       "      <td>A content management system (CMS) and a transl...</td>\n",
       "      <td>None</td>\n",
       "      <td>2019-03-12</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>US</td>\n",
       "      <td>org_Vbc6obpnxWM42d0HjlXY</td>\n",
       "      <td>47.6064</td>\n",
       "      <td>47.6064|-122.3308</td>\n",
       "      <td>-122.331</td>\n",
       "      <td>WA</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>US</td>\n",
       "      <td>9177341-1</td>\n",
       "      <td>47.6064</td>\n",
       "      <td>47.6064|-122.3308</td>\n",
       "      <td>-122.331</td>\n",
       "      <td>WA</td>\n",
       "      <td>B1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>26</td>\n",
       "      <td>10229113</td>\n",
       "      <td>895</td>\n",
       "      <td>Leveraging content dimensions during the trans...</td>\n",
       "      <td>utility</td>\n",
       "      <td>2019</td>\n",
       "      <td>[{'pct_102_date': None, 'pct_371_date': None, ...</td>\n",
       "      <td>[{'rawinventor_first_name': 'Thibault Pierre',...</td>\n",
       "      <td>[{'uspc_first_seen_date': None, 'uspc_last_see...</td>\n",
       "      <td>[{'wipo_field_id': None, 'wipo_field_title': N...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                IPCs  \\\n",
       "0  [{'ipc_action_date': '2019-03-12', 'ipc_class'...   \n",
       "1  [{'ipc_action_date': '2019-03-12', 'ipc_class'...   \n",
       "2  [{'ipc_action_date': '2019-03-12', 'ipc_class'...   \n",
       "\n",
       "                               application_citations  \\\n",
       "0  [{'appcit_app_number': '2002/20020077823', 'ap...   \n",
       "1  [{'appcit_app_number': '2002/20020138265', 'ap...   \n",
       "2  [{'appcit_app_number': '2001/20010029455', 'ap...   \n",
       "\n",
       "                                        applications  \\\n",
       "0  [{'app_country': 'US', 'app_date': '2013-07-26...   \n",
       "1  [{'app_country': 'US', 'app_date': '2017-09-11...   \n",
       "2  [{'app_country': 'US', 'app_date': '2016-09-28...   \n",
       "\n",
       "                                           assignees  \\\n",
       "0  [{'assignee_city': 'Burlington', 'assignee_cou...   \n",
       "1  [{'assignee_city': 'Mountain View', 'assignee_...   \n",
       "2  [{'assignee_city': 'Seattle', 'assignee_countr...   \n",
       "\n",
       "                                       cited_patents  \\\n",
       "0  [{'cited_patent_category': 'cited by examiner'...   \n",
       "1  [{'cited_patent_category': 'cited by applicant...   \n",
       "2  [{'cited_patent_category': 'cited by applicant...   \n",
       "\n",
       "                                     citedby_patents  \\\n",
       "0  [{'citedby_patent_category': None, 'citedby_pa...   \n",
       "1  [{'citedby_patent_category': None, 'citedby_pa...   \n",
       "2  [{'citedby_patent_category': None, 'citedby_pa...   \n",
       "\n",
       "                                                cpcs detail_desc_length  \\\n",
       "0  [{'cpc_category': None, 'cpc_first_seen_date':...              11570   \n",
       "1  [{'cpc_category': None, 'cpc_first_seen_date':...              28118   \n",
       "2  [{'cpc_category': None, 'cpc_first_seen_date':...             119654   \n",
       "\n",
       "                                           examiners  \\\n",
       "0  [{'examiner_first_name': 'Michael N', 'examine...   \n",
       "1  [{'examiner_first_name': 'Shreyans A', 'examin...   \n",
       "2  [{'examiner_first_name': 'Jialong', 'examiner_...   \n",
       "\n",
       "                                    foreign_priority  \\\n",
       "0  [{'forprior_country': None, 'forprior_date': N...   \n",
       "1  [{'forprior_country': None, 'forprior_date': N...   \n",
       "2  [{'forprior_country': None, 'forprior_date': N...   \n",
       "\n",
       "                                       gov_interests  \\\n",
       "0  [{'govint_contract_award_number': None, 'govin...   \n",
       "1  [{'govint_contract_award_number': None, 'govin...   \n",
       "2  [{'govint_contract_award_number': None, 'govin...   \n",
       "\n",
       "                                           inventors  \\\n",
       "0  [{'inventor_city': 'Newton', 'inventor_country...   \n",
       "1  [{'inventor_city': 'Adliswil', 'inventor_count...   \n",
       "2  [{'inventor_city': 'Seattle', 'inventor_countr...   \n",
       "\n",
       "                                             lawyers  \\\n",
       "0  [{'lawyer_first_name': None, 'lawyer_first_see...   \n",
       "1  [{'lawyer_first_name': None, 'lawyer_first_see...   \n",
       "2  [{'lawyer_first_name': None, 'lawyer_first_see...   \n",
       "\n",
       "                                               nbers  \\\n",
       "0  [{'nber_category_id': None, 'nber_category_tit...   \n",
       "1  [{'nber_category_id': None, 'nber_category_tit...   \n",
       "2  [{'nber_category_id': None, 'nber_category_tit...   \n",
       "\n",
       "                                     patent_abstract  \\\n",
       "0  Designing a natural language understanding (NL...   \n",
       "1  Methods, systems, and apparatus, including com...   \n",
       "2  A content management system (CMS) and a transl...   \n",
       "\n",
       "  patent_average_processing_time patent_date patent_firstnamed_assignee_city  \\\n",
       "0                           None  2019-03-12                      Burlington   \n",
       "1                           None  2019-03-12                   Mountain View   \n",
       "2                           None  2019-03-12                         Seattle   \n",
       "\n",
       "  patent_firstnamed_assignee_country patent_firstnamed_assignee_id  \\\n",
       "0                                 US      org_ID497r4tFbCIaMBjGAST   \n",
       "1                                 US      org_p6ofWD2xFNSnyYkj6wpA   \n",
       "2                                 US      org_Vbc6obpnxWM42d0HjlXY   \n",
       "\n",
       "  patent_firstnamed_assignee_latitude patent_firstnamed_assignee_location_id  \\\n",
       "0                             42.5047                       42.5047|-71.1961   \n",
       "1                             37.3861                      37.3861|-122.0828   \n",
       "2                             47.6064                      47.6064|-122.3308   \n",
       "\n",
       "  patent_firstnamed_assignee_longitude patent_firstnamed_assignee_state  \\\n",
       "0                             -71.1961                               MA   \n",
       "1                             -122.083                               CA   \n",
       "2                             -122.331                               WA   \n",
       "\n",
       "  patent_firstnamed_inventor_city patent_firstnamed_inventor_country  \\\n",
       "0                          Newton                                 US   \n",
       "1                        Adliswil                                 CH   \n",
       "2                         Seattle                                 US   \n",
       "\n",
       "  patent_firstnamed_inventor_id patent_firstnamed_inventor_latitude  \\\n",
       "0                     7788103-1                             42.3369   \n",
       "1                     8352247-1                             47.3119   \n",
       "2                     9177341-1                             47.6064   \n",
       "\n",
       "  patent_firstnamed_inventor_location_id patent_firstnamed_inventor_longitude  \\\n",
       "0                       42.3369|-71.2097                             -71.2097   \n",
       "1                         47.3119|8.5287                               8.5287   \n",
       "2                      47.6064|-122.3308                             -122.331   \n",
       "\n",
       "  patent_firstnamed_inventor_state patent_kind patent_num_cited_by_us_patents  \\\n",
       "0                               MA          B2                              0   \n",
       "1                             None          B1                              0   \n",
       "2                               WA          B1                              0   \n",
       "\n",
       "  patent_num_claims patent_num_combined_citations  \\\n",
       "0                19                            31   \n",
       "1                20                            15   \n",
       "2                20                            74   \n",
       "\n",
       "  patent_num_foreign_citations patent_num_us_application_citations  \\\n",
       "0                            0                                  26   \n",
       "1                            0                                   7   \n",
       "2                            0                                  48   \n",
       "\n",
       "  patent_num_us_patent_citations patent_number patent_processing_time  \\\n",
       "0                              5      10229106                   2055   \n",
       "1                              8      10229109                    547   \n",
       "2                             26      10229113                    895   \n",
       "\n",
       "                                        patent_title patent_type patent_year  \\\n",
       "0  Initializing a workspace for building a natura...     utility        2019   \n",
       "1               Allowing spelling of arbitrary words     utility        2019   \n",
       "2  Leveraging content dimensions during the trans...     utility        2019   \n",
       "\n",
       "                                            pct_data  \\\n",
       "0  [{'pct_102_date': None, 'pct_371_date': None, ...   \n",
       "1  [{'pct_102_date': None, 'pct_371_date': None, ...   \n",
       "2  [{'pct_102_date': None, 'pct_371_date': None, ...   \n",
       "\n",
       "                                        rawinventors  \\\n",
       "0  [{'rawinventor_first_name': 'Jeffrey N.', 'raw...   \n",
       "1  [{'rawinventor_first_name': 'Evgeny A.', 'rawi...   \n",
       "2  [{'rawinventor_first_name': 'Thibault Pierre',...   \n",
       "\n",
       "                                               uspcs  \\\n",
       "0  [{'uspc_first_seen_date': None, 'uspc_last_see...   \n",
       "1  [{'uspc_first_seen_date': None, 'uspc_last_see...   \n",
       "2  [{'uspc_first_seen_date': None, 'uspc_last_see...   \n",
       "\n",
       "                                               wipos  \n",
       "0  [{'wipo_field_id': None, 'wipo_field_title': N...  \n",
       "1  [{'wipo_field_id': None, 'wipo_field_title': N...  \n",
       "2  [{'wipo_field_id': None, 'wipo_field_title': N...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract data from response\n",
    "data = results['patents']\n",
    "# data[0]\n",
    "df = pd.DataFrame(data)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ser = df_assignees['assignee_id'].apply(pd.Series)\n",
    "# len(ser)\n",
    "# ser.duplicated()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subset dataframe with non-nested patent data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['IPCs', 'application_citations', 'applications', 'assignees',\n",
       "       'cited_patents', 'citedby_patents', 'cpcs', 'detail_desc_length',\n",
       "       'examiners', 'foreign_priority', 'gov_interests', 'inventors',\n",
       "       'lawyers', 'nbers', 'patent_abstract', 'patent_average_processing_time',\n",
       "       'patent_date', 'patent_firstnamed_assignee_city',\n",
       "       'patent_firstnamed_assignee_country', 'patent_firstnamed_assignee_id',\n",
       "       'patent_firstnamed_assignee_latitude',\n",
       "       'patent_firstnamed_assignee_location_id',\n",
       "       'patent_firstnamed_assignee_longitude',\n",
       "       'patent_firstnamed_assignee_state', 'patent_firstnamed_inventor_city',\n",
       "       'patent_firstnamed_inventor_country', 'patent_firstnamed_inventor_id',\n",
       "       'patent_firstnamed_inventor_latitude',\n",
       "       'patent_firstnamed_inventor_location_id',\n",
       "       'patent_firstnamed_inventor_longitude',\n",
       "       'patent_firstnamed_inventor_state', 'patent_kind',\n",
       "       'patent_num_cited_by_us_patents', 'patent_num_claims',\n",
       "       'patent_num_combined_citations', 'patent_num_foreign_citations',\n",
       "       'patent_num_us_application_citations', 'patent_num_us_patent_citations',\n",
       "       'patent_number', 'patent_processing_time', 'patent_title',\n",
       "       'patent_type', 'patent_year', 'pct_data', 'rawinventors', 'uspcs',\n",
       "       'wipos'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patent_number</th>\n",
       "      <th>patent_date</th>\n",
       "      <th>patent_title</th>\n",
       "      <th>patent_abstract</th>\n",
       "      <th>patent_firstnamed_assignee_id</th>\n",
       "      <th>patent_year</th>\n",
       "      <th>patent_type</th>\n",
       "      <th>patent_kind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10229106</td>\n",
       "      <td>2019-03-12</td>\n",
       "      <td>Initializing a workspace for building a natura...</td>\n",
       "      <td>Designing a natural language understanding (NL...</td>\n",
       "      <td>org_ID497r4tFbCIaMBjGAST</td>\n",
       "      <td>2019</td>\n",
       "      <td>utility</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10229109</td>\n",
       "      <td>2019-03-12</td>\n",
       "      <td>Allowing spelling of arbitrary words</td>\n",
       "      <td>Methods, systems, and apparatus, including com...</td>\n",
       "      <td>org_p6ofWD2xFNSnyYkj6wpA</td>\n",
       "      <td>2019</td>\n",
       "      <td>utility</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10229113</td>\n",
       "      <td>2019-03-12</td>\n",
       "      <td>Leveraging content dimensions during the trans...</td>\n",
       "      <td>A content management system (CMS) and a transl...</td>\n",
       "      <td>org_Vbc6obpnxWM42d0HjlXY</td>\n",
       "      <td>2019</td>\n",
       "      <td>utility</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  patent_number patent_date  \\\n",
       "0      10229106  2019-03-12   \n",
       "1      10229109  2019-03-12   \n",
       "2      10229113  2019-03-12   \n",
       "\n",
       "                                        patent_title  \\\n",
       "0  Initializing a workspace for building a natura...   \n",
       "1               Allowing spelling of arbitrary words   \n",
       "2  Leveraging content dimensions during the trans...   \n",
       "\n",
       "                                     patent_abstract  \\\n",
       "0  Designing a natural language understanding (NL...   \n",
       "1  Methods, systems, and apparatus, including com...   \n",
       "2  A content management system (CMS) and a transl...   \n",
       "\n",
       "  patent_firstnamed_assignee_id patent_year patent_type patent_kind  \n",
       "0      org_ID497r4tFbCIaMBjGAST        2019     utility          B2  \n",
       "1      org_p6ofWD2xFNSnyYkj6wpA        2019     utility          B1  \n",
       "2      org_Vbc6obpnxWM42d0HjlXY        2019     utility          B1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['patent_number', \n",
    "         'patent_date', \n",
    "         'patent_title',\n",
    "         'patent_abstract', \n",
    "         'patent_firstnamed_assignee_id', \n",
    "         'patent_year', \n",
    "         'patent_type', \n",
    "         'patent_kind']]\n",
    "df.head(3)\n",
    "\n",
    "# other field options - uncomment to use\n",
    "# df = df[['patent_number', \n",
    "#          'patent_date', \n",
    "#          'patent_title',\n",
    "#          'patent_abstract', \n",
    "#          'patent_firstnamed_assignee_id',\n",
    "#          'patent_firstnamed_assignee_location_id',\n",
    "#          'patent_firstnamed_assignee_latitude',\n",
    "#          'patent_firstnamed_assignee_longitude',\n",
    "#          'patent_firstnamed_assignee_city',\n",
    "#          'patent_firstnamed_assignee_state',\n",
    "#          'patent_firstnamed_assignee_country', \n",
    "#          'patent_firstnamed_inventor_id',\n",
    "#          'patent_firstnamed_inventor_location_id',\n",
    "#          'patent_firstnamed_inventor_latitude',\n",
    "#          'patent_firstnamed_inventor_longitude',\n",
    "#          'patent_firstnamed_inventor_city',\n",
    "#          'patent_firstnamed_inventor_state',\n",
    "#          'patent_firstnamed_inventor_country',\n",
    "#          'patent_year', \n",
    "#          'patent_type', \n",
    "#          'patent_kind',\n",
    "#          'patent_processing_time', \n",
    "#          'patent_num_us_application_citations', \n",
    "#          'patent_num_us_patent_citations', \n",
    "#          'patent_num_foreign_citations', \n",
    "#          'patent_num_combined_citations', \n",
    "#          'patent_num_claims', \n",
    "#          'patent_num_cited_by_us_patents',\n",
    "#          'detail_desc_length']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2482"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "561"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 561 different assignees\n",
    "len(df.patent_firstnamed_assignee_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "org_q9Bn28RHhpYrQjKvraAH    497\n",
       "org_JZguWDMfFOBX2wBI9pnD    129\n",
       "org_ID497r4tFbCIaMBjGAST     88\n",
       "org_rDyHZBYWMcBEtnkHt05L     80\n",
       "org_p6ofWD2xFNSnyYkj6wpA     57\n",
       "org_EilEWQcC6UiqHcSGx9mb     56\n",
       "org_ccMMcUijAIsKIxUqMTyP     49\n",
       "org_Vbc6obpnxWM42d0HjlXY     41\n",
       "org_9D8x1qL3IRASp6GG7Glu     29\n",
       "org_2wAdIFKssfcLHpZq0u4H     26\n",
       "org_iwO2oOJ6VIBd9fAuP7G6     25\n",
       "org_70D1lR89kQnFiCFdJ6s5     21\n",
       "org_vojVnDkT9CamDETqbqJC     20\n",
       "org_FMQQGwWD4see8cTUvBeX     19\n",
       "org_jcMFnF4MRSJNjmqziFa9     18\n",
       "org_GUiR0pTTvKdhSuybuvMR     17\n",
       "org_9iGi89m70dsoKPnaLltP     17\n",
       "org_CK0tqpzs4px2nSotRfKl     16\n",
       "org_XWf19ywansX8qlLlHjGG     16\n",
       "org_s0LaUsnsry8sCex6uVmg     15\n",
       "org_vx2AiPnNxs2QH1kizUy6     14\n",
       "org_vQqsKNGqbuYMayjlKP0G     14\n",
       "org_krHJCqMYeOjju2UJXges     14\n",
       "org_BhFWbZ5cX0tSnPE1cE4T     13\n",
       "org_I59YOZJPMXh8rsx5bADw     13\n",
       "org_L08XqsTCahw2gYnyMv0U     12\n",
       "org_JcRuyjhZvN7yR3keFPz4     12\n",
       "org_dddCYZXWKhhDvCTH3ler     11\n",
       "org_UhsXRNeVCGJRfxG5GhRk     10\n",
       "org_NXkCV61xXxkp7krqI771     10\n",
       "                           ... \n",
       "org_rVRpgSC0jMUwrZHOmtc5      1\n",
       "org_jEcRgKfHOxTdKEukdR2f      1\n",
       "org_G5wllurwvDuP4fLZGwME      1\n",
       "org_MSJmESoyiU3fbbTejev0      1\n",
       "org_39vGWYa0TwpBtly7fQIq      1\n",
       "org_rDg9FpmP9YdQO2AwPfjo      1\n",
       "org_Q8ECmEg8wuJoajCb9Cwj      1\n",
       "org_be5Rol3utmx0oOnFv7NO      1\n",
       "org_5EXmm2cjNVpXyqxccdhK      1\n",
       "org_wzXYA0wbff9UKyzAtXlV      1\n",
       "org_BKBsDVYOETs9bxymQoyH      1\n",
       "org_m86HY5vFWgyLjYcvLrBI      1\n",
       "org_tpINMxL4kIEmH4DpHiOL      1\n",
       "org_7QdflaMQa5eDWCxVtjti      1\n",
       "org_wnYXubjYG80feUApY0xw      1\n",
       "org_hjaDAvJqFpbMLxgTJ1RT      1\n",
       "org_rONKZ27lK6aueiVCYUCP      1\n",
       "org_S6aHlpRJyCjUReNkXv7H      1\n",
       "org_MogTb8GdE0u278CgzZJe      1\n",
       "org_NcHlD5czwQWcmJXs0u85      1\n",
       "org_3GLkEdQ1kO4QAaMLyC8P      1\n",
       "org_tq5y1mxpMRUTzQY1nGAw      1\n",
       "org_vG9QC98wlZnw1ijKoPk0      1\n",
       "org_rGrTOVRIsnln8BjhEMKM      1\n",
       "org_xbYQ67f5pKjKnRLIjefD      1\n",
       "org_JIyWleZLCeZmeRYKfBQp      1\n",
       "org_BZE4mqituXJtUiJY7O2X      1\n",
       "org_RqVWeNaYVtyE5yGCzNS2      1\n",
       "org_m5UTXPxo2ncC5Un10pa6      1\n",
       "org_AZOvd4hR8hLHPTNjMn1Y      1\n",
       "Name: patent_firstnamed_assignee_id, Length: 560, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.patent_firstnamed_assignee_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Inspecting assignees nested data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_assignees' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-41056f5d1857>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_assignees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_assignees' is not defined"
     ]
    }
   ],
   "source": [
    "df_assignees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lend(df_assignees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_assignees = json_normalize(results['patents'], record_path=['assignees'], meta=['patent_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       False\n",
       "1       False\n",
       "2       False\n",
       "3       False\n",
       "4       False\n",
       "5       False\n",
       "6       False\n",
       "7       False\n",
       "8       False\n",
       "9       False\n",
       "10      False\n",
       "11      False\n",
       "12      False\n",
       "13      False\n",
       "14      False\n",
       "15      False\n",
       "16      False\n",
       "17      False\n",
       "18      False\n",
       "19      False\n",
       "20      False\n",
       "21      False\n",
       "22      False\n",
       "23      False\n",
       "24      False\n",
       "25      False\n",
       "26      False\n",
       "27      False\n",
       "28      False\n",
       "29      False\n",
       "        ...  \n",
       "2472    False\n",
       "2473    False\n",
       "2474    False\n",
       "2475    False\n",
       "2476    False\n",
       "2477    False\n",
       "2478    False\n",
       "2479    False\n",
       "2480    False\n",
       "2481    False\n",
       "2482    False\n",
       "2483    False\n",
       "2484    False\n",
       "2485    False\n",
       "2486    False\n",
       "2487    False\n",
       "2488    False\n",
       "2489    False\n",
       "2490    False\n",
       "2491    False\n",
       "2492    False\n",
       "2493    False\n",
       "2494    False\n",
       "2495    False\n",
       "2496    False\n",
       "2497    False\n",
       "2498    False\n",
       "2499    False\n",
       "2500    False\n",
       "2501    False\n",
       "Length: 2502, dtype: bool"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_assignees.duplicated('patent_number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assignee_city</th>\n",
       "      <th>assignee_country</th>\n",
       "      <th>assignee_county</th>\n",
       "      <th>assignee_county_fips</th>\n",
       "      <th>assignee_first_name</th>\n",
       "      <th>assignee_first_seen_date</th>\n",
       "      <th>assignee_id</th>\n",
       "      <th>assignee_key_id</th>\n",
       "      <th>assignee_last_name</th>\n",
       "      <th>assignee_last_seen_date</th>\n",
       "      <th>assignee_lastknown_city</th>\n",
       "      <th>assignee_lastknown_country</th>\n",
       "      <th>assignee_lastknown_latitude</th>\n",
       "      <th>assignee_lastknown_location_id</th>\n",
       "      <th>assignee_lastknown_longitude</th>\n",
       "      <th>assignee_lastknown_state</th>\n",
       "      <th>assignee_latitude</th>\n",
       "      <th>assignee_location_id</th>\n",
       "      <th>assignee_longitude</th>\n",
       "      <th>assignee_organization</th>\n",
       "      <th>assignee_sequence</th>\n",
       "      <th>assignee_state</th>\n",
       "      <th>assignee_state_fips</th>\n",
       "      <th>assignee_total_num_inventors</th>\n",
       "      <th>assignee_total_num_patents</th>\n",
       "      <th>assignee_type</th>\n",
       "      <th>patent_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1911</th>\n",
       "      <td>Tokyo</td>\n",
       "      <td>JP</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>2007-10-16</td>\n",
       "      <td>org_SEywROQVbKV7Zj6CtfEE</td>\n",
       "      <td>344976</td>\n",
       "      <td>None</td>\n",
       "      <td>2007-10-16</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>JP</td>\n",
       "      <td>35.685</td>\n",
       "      <td>35.685|139.7514</td>\n",
       "      <td>139.751</td>\n",
       "      <td>None</td>\n",
       "      <td>35.685</td>\n",
       "      <td>35.685|139.7514</td>\n",
       "      <td>139.751</td>\n",
       "      <td>Fuji Xexox Co., Ltd.</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7283958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     assignee_city assignee_country assignee_county assignee_county_fips  \\\n",
       "1911         Tokyo               JP            None                    0   \n",
       "\n",
       "     assignee_first_name assignee_first_seen_date               assignee_id  \\\n",
       "1911                None               2007-10-16  org_SEywROQVbKV7Zj6CtfEE   \n",
       "\n",
       "     assignee_key_id assignee_last_name assignee_last_seen_date  \\\n",
       "1911          344976               None              2007-10-16   \n",
       "\n",
       "     assignee_lastknown_city assignee_lastknown_country  \\\n",
       "1911                   Tokyo                         JP   \n",
       "\n",
       "     assignee_lastknown_latitude assignee_lastknown_location_id  \\\n",
       "1911                      35.685                35.685|139.7514   \n",
       "\n",
       "     assignee_lastknown_longitude assignee_lastknown_state assignee_latitude  \\\n",
       "1911                      139.751                     None            35.685   \n",
       "\n",
       "     assignee_location_id assignee_longitude assignee_organization  \\\n",
       "1911      35.685|139.7514            139.751  Fuji Xexox Co., Ltd.   \n",
       "\n",
       "     assignee_sequence assignee_state assignee_state_fips  \\\n",
       "1911                 0           None                   0   \n",
       "\n",
       "     assignee_total_num_inventors assignee_total_num_patents assignee_type  \\\n",
       "1911                            4                          1             3   \n",
       "\n",
       "     patent_number  \n",
       "1911       7283958  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_assignees[df_assignees['assignee_id'] == \"org_SEywROQVbKV7Zj6CtfEE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assignee_city</th>\n",
       "      <th>assignee_country</th>\n",
       "      <th>assignee_county</th>\n",
       "      <th>assignee_county_fips</th>\n",
       "      <th>assignee_first_name</th>\n",
       "      <th>assignee_first_seen_date</th>\n",
       "      <th>assignee_id</th>\n",
       "      <th>assignee_key_id</th>\n",
       "      <th>assignee_last_name</th>\n",
       "      <th>assignee_last_seen_date</th>\n",
       "      <th>assignee_lastknown_city</th>\n",
       "      <th>assignee_lastknown_country</th>\n",
       "      <th>assignee_lastknown_latitude</th>\n",
       "      <th>assignee_lastknown_location_id</th>\n",
       "      <th>assignee_lastknown_longitude</th>\n",
       "      <th>assignee_lastknown_state</th>\n",
       "      <th>assignee_latitude</th>\n",
       "      <th>assignee_location_id</th>\n",
       "      <th>assignee_longitude</th>\n",
       "      <th>assignee_organization</th>\n",
       "      <th>assignee_sequence</th>\n",
       "      <th>assignee_state</th>\n",
       "      <th>assignee_state_fips</th>\n",
       "      <th>assignee_total_num_inventors</th>\n",
       "      <th>assignee_total_num_patents</th>\n",
       "      <th>assignee_type</th>\n",
       "      <th>patent_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Beijing</td>\n",
       "      <td>CN</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>1990-04-17</td>\n",
       "      <td>org_myRnscKfY7JOy5h8LVrg</td>\n",
       "      <td>267177</td>\n",
       "      <td>None</td>\n",
       "      <td>2019-02-19</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>CN</td>\n",
       "      <td>39.9042</td>\n",
       "      <td>39.9042|116.4074</td>\n",
       "      <td>116.407</td>\n",
       "      <td>None</td>\n",
       "      <td>39.9042</td>\n",
       "      <td>39.9042|116.4074</td>\n",
       "      <td>116.407</td>\n",
       "      <td>Peking University</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>463</td>\n",
       "      <td>224</td>\n",
       "      <td>3</td>\n",
       "      <td>10210245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Shenzhen</td>\n",
       "      <td>CN</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>2009-06-23</td>\n",
       "      <td>org_O0GfNE8msswIVOwTLezZ</td>\n",
       "      <td>282280</td>\n",
       "      <td>None</td>\n",
       "      <td>2019-03-12</td>\n",
       "      <td>Shenzhen</td>\n",
       "      <td>CN</td>\n",
       "      <td>22.5333</td>\n",
       "      <td>22.5333|114.1333</td>\n",
       "      <td>114.133</td>\n",
       "      <td>None</td>\n",
       "      <td>22.5333</td>\n",
       "      <td>22.5333|114.1333</td>\n",
       "      <td>114.133</td>\n",
       "      <td>TENCENT TECHNOLOGY (SHENZHEN) COMPANY LIMITED</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1977</td>\n",
       "      <td>1421</td>\n",
       "      <td>3</td>\n",
       "      <td>10210245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   assignee_city assignee_country assignee_county assignee_county_fips  \\\n",
       "36       Beijing               CN            None                    0   \n",
       "37      Shenzhen               CN            None                    0   \n",
       "\n",
       "   assignee_first_name assignee_first_seen_date               assignee_id  \\\n",
       "36                None               1990-04-17  org_myRnscKfY7JOy5h8LVrg   \n",
       "37                None               2009-06-23  org_O0GfNE8msswIVOwTLezZ   \n",
       "\n",
       "   assignee_key_id assignee_last_name assignee_last_seen_date  \\\n",
       "36          267177               None              2019-02-19   \n",
       "37          282280               None              2019-03-12   \n",
       "\n",
       "   assignee_lastknown_city assignee_lastknown_country  \\\n",
       "36                 Beijing                         CN   \n",
       "37                Shenzhen                         CN   \n",
       "\n",
       "   assignee_lastknown_latitude assignee_lastknown_location_id  \\\n",
       "36                     39.9042               39.9042|116.4074   \n",
       "37                     22.5333               22.5333|114.1333   \n",
       "\n",
       "   assignee_lastknown_longitude assignee_lastknown_state assignee_latitude  \\\n",
       "36                      116.407                     None           39.9042   \n",
       "37                      114.133                     None           22.5333   \n",
       "\n",
       "   assignee_location_id assignee_longitude  \\\n",
       "36     39.9042|116.4074            116.407   \n",
       "37     22.5333|114.1333            114.133   \n",
       "\n",
       "                            assignee_organization assignee_sequence  \\\n",
       "36                              Peking University                 0   \n",
       "37  TENCENT TECHNOLOGY (SHENZHEN) COMPANY LIMITED                 1   \n",
       "\n",
       "   assignee_state assignee_state_fips assignee_total_num_inventors  \\\n",
       "36           None                   0                          463   \n",
       "37           None                   0                         1977   \n",
       "\n",
       "   assignee_total_num_patents assignee_type patent_number  \n",
       "36                        224             3      10210245  \n",
       "37                       1421             3      10210245  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_assignees[df_assignees['patent_number'] == \"10210245\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patent_number</th>\n",
       "      <th>patent_date</th>\n",
       "      <th>patent_title</th>\n",
       "      <th>patent_abstract</th>\n",
       "      <th>patent_firstnamed_assignee_id</th>\n",
       "      <th>patent_year</th>\n",
       "      <th>patent_type</th>\n",
       "      <th>patent_kind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>10210245</td>\n",
       "      <td>2019-02-19</td>\n",
       "      <td>Natural language question answering method and...</td>\n",
       "      <td>A natural language question answering method a...</td>\n",
       "      <td>org_myRnscKfY7JOy5h8LVrg</td>\n",
       "      <td>2019</td>\n",
       "      <td>utility</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patent_number patent_date  \\\n",
       "36      10210245  2019-02-19   \n",
       "\n",
       "                                         patent_title  \\\n",
       "36  Natural language question answering method and...   \n",
       "\n",
       "                                      patent_abstract  \\\n",
       "36  A natural language question answering method a...   \n",
       "\n",
       "   patent_firstnamed_assignee_id patent_year patent_type patent_kind  \n",
       "36      org_myRnscKfY7JOy5h8LVrg        2019     utility          B2  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['patent_number'] == \"10210245\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other nested tables for investigation - uncomment to use\n",
    "\n",
    "# json_normalize(results['patents'][0], record_path='applications')\n",
    "\n",
    "# inspect nested datasets, column by column\n",
    "\n",
    "# json_normalize(results['patents'][0])\n",
    "# json_normalize(results['patents'][0], record_path='IPCs')\n",
    "# json_normalize(results['patents'][0], record_path='application_citations')\n",
    "# json_normalize(results['patents'][0], record_path='applications')\n",
    "# json_normalize(results['patents'][2], record_path='assignees')\n",
    "# json_normalize(results['patents'][0], record_path='cited_patents')\n",
    "# json_normalize(results['patents'][0], record_path='citedby_patents')\n",
    "# json_normalize(results['patents'][24], record_path='cpcs')\n",
    "# json_normalize(results['patents'][0], record_path='examiners')\n",
    "# json_normalize(results['patents'][0], record_path='foreign_priority')\n",
    "# json_normalize(results['patents'][0], record_path='gov_interests')\n",
    "# json_normalize(results['patents'][0], record_path='inventors')\n",
    "# json_normalize(results['patents'][0], record_path='lawyers')\n",
    "# json_normalize(results['patents'][0], record_path='nbers')\n",
    "# json_normalize(results['patents'][0], record_path='pct_data')\n",
    "# json_normalize(results['patents'][0], record_path='rawinventors')\n",
    "# json_normalize(results['patents'][0:5], record_path='uspcs')\n",
    "# json_normalize(results['patents'][0], record_path='examiners')\n",
    "# json_normalize(results['patents'][0], record_path='wipos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Initializing a workspace for building a natura...\n",
       "1    Allowing spelling of arbitrary words Methods, ...\n",
       "2    Leveraging content dimensions during the trans...\n",
       "Name: patent_title_abstract, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['patent_title_abstract'] = df.patent_title + ' ' + df.patent_abstract\n",
    "df.patent_title_abstract.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map values of series according to input correspondence\n",
    "# substitute each value in series derived from NLTK word_tokenize function\n",
    "text_data = df['patent_title_abstract'].map(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the first 3 items in `data` to see how everything looks \n",
    "text_data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate word2vec model\n",
    "# window: maximum distance between the current and predicted word within a sentence\n",
    "# size: number of dimensions for word vectors\n",
    "# min_count: min word frequency in vocab cutoff threshhold\n",
    "# workers param: number of worker threads to train model, for faster training with multicore machines\n",
    "model_w2v = Word2Vec(text_data, size=100, window=5, min_count=1, workers=4)\n",
    "model_w2v.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'corpus_count' returns number of sentences in dataset, in this case, 200K sentences\n",
    "model_w2v.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train updates the model’s neural weights from a sequence of sentences\n",
    "# training is streamed, meaning sentences can be a generator that reads input data from disk on-the-fly,\n",
    "# without loading the entire corpus into RAM. This also means you can continue training the model later:\n",
    "\n",
    "model_w2v.train(text_data, total_examples=model_w2v.corpus_count, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .wv separates trained word vectors in a KeyedVectors instance and assigns to var so don't need full model state\n",
    "# (don’t need to continue training) by discarding state, we have a much smaller and faster object that can be\n",
    "# mapped for fast loading and sharing the vectors in RAM between processes\n",
    "\n",
    "word_vectors = model_w2v.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_w2v.trainables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_words_list = ['computer', 'language', 'user']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets the probability distribution of the center word given context words\n",
    "model_w2v.predict_output_word(context_words_list, topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute cosine similarity & return most similar words to a word passed to function\n",
    "word_vectors.most_similar(positive='generation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get word vector for a given word\n",
    "word_vectors['generate']\n",
    "\n",
    "# returns word vectors for entire vocabulary(dictionary)\n",
    "word_vectors.vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features\n",
    "data = df['patent_title_abstract'].map(word_tokenize).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target\n",
    "target = df.patent_firstnamed_assignee_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download zip file of GloVe model pretrained weights from Stanford NLP\n",
    "# !wget http://nlp.stanford.edu/data/glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate total vocab of our dataset by adding every word in the dataset into a python set object. \n",
    "total_vocabulary = set(word for headline in data for word in headline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of tokens in this dataset\n",
    "len(total_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code\n",
    "glove = {}\n",
    "with open('glove.6B.50d.txt', 'rb') as f:\n",
    "    for line in f:\n",
    "        parts = line.split()\n",
    "        word = parts[0].decode('utf-8')\n",
    "        if word in total_vocabulary:\n",
    "            vector = np.array(parts[1:], dtype=np.float32)\n",
    "            glove[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove['generate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code\n",
    "class W2vVectorizer(object):\n",
    "    \n",
    "    def __init__(self, w2v):\n",
    "        # takes in a dictionary of words and vectors as input\n",
    "        self.w2v = w2v\n",
    "        if len(w2v) == 0:\n",
    "            self.dimensions = 0\n",
    "        else:\n",
    "            self.dimensions = len(w2v[next(iter(glove))])\n",
    "    \n",
    "    # Note from Mike: Even though it doesn't do anything, it's required that this object implement a fit method or else\n",
    "    # It can't be used in a sklearn Pipeline. \n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "            \n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.w2v[w] for w in words if w in self.w2v]\n",
    "                   or [np.zeros(self.dimensions)], axis=0) for words in X])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP NNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, Dense, LSTM, Embedding\n",
    "from keras.layers import Dropout, Activation, Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.preprocessing import text, sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = text.Tokenizer(num_words=20000)\n",
    "tokenizer.fit_on_texts(list(df.combined_text))\n",
    "list_tokenized_headlines = tokenizer.texts_to_sequences(df.combined_text)\n",
    "X_t = sequence.pad_sequences(list_tokenized_headlines, maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 128\n",
    "input_ = Input(shape=(100,))\n",
    "x = Embedding(20000, embedding_size)(input_)\n",
    "x = LSTM(25, return_sequences=True)(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(50, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "# There are 41 different possible classes, so we use 41 neurons in our output layer\n",
    "x = Dense(41, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=input_, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_t, y, epochs=2, batch_size=32, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features\n",
    "data = df['patent_title_abstract'].map(word_tokenize).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Initializing a workspace for building a natural language understanding system Designing a natural language understanding (NLU) model for an application from scratch can be difficult for non-experts. A system can simplify the design process by providing an interface allowing a designer to input example usage sentences and build an NLU model based on presented matches to those example sentences. In one embodiment, a method for initializing a workspace for building an NLU system includes parsing a sample sentence to select at least one candidate stub grammar from among multiple candidate stub grammars. The method can include presenting, to a user, respective representations of the candidate stub grammars selected by the parsing of the sample sentence. The method can include enabling the user to choose one of the respective representations of the candidate stub grammars. The method can include adding to the workspace a stub grammar corresponding to the representation of the candidate stub grammar chosen by the user.'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['patent_title_abstract'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_word_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate tf tokenizer\n",
    "tokenizer = text.Tokenizer(lower=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  tokenize, lower, clean punctuation\n",
    "tokenizer.fit_on_texts(list(df.patent_title_abstract))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tokenized_headlines = tokenizer.sequences_to_texts_generator?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform each word(token?) in document to sequence of integers that index word strings\n",
    "list_tokenized_pat_docs = tokenizer.texts_to_sequences(df.patent_title_abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pads sequences to the same length. returns np array with shape (len(sequences), maxlen)\n",
    "X_t = sequence.pad_sequences(list_tokenized_pat_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_t[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Initializing',\n",
       " 'a',\n",
       " 'workspace',\n",
       " 'for',\n",
       " 'building',\n",
       " 'a',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'understanding',\n",
       " 'system',\n",
       " 'Designing',\n",
       " 'a',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'understanding',\n",
       " '(',\n",
       " 'NLU',\n",
       " ')',\n",
       " 'model',\n",
       " 'for',\n",
       " 'an',\n",
       " 'application',\n",
       " 'from',\n",
       " 'scratch',\n",
       " 'can',\n",
       " 'be',\n",
       " 'difficult',\n",
       " 'for',\n",
       " 'non-experts',\n",
       " '.',\n",
       " 'A',\n",
       " 'system',\n",
       " 'can',\n",
       " 'simplify',\n",
       " 'the',\n",
       " 'design',\n",
       " 'process',\n",
       " 'by',\n",
       " 'providing',\n",
       " 'an',\n",
       " 'interface',\n",
       " 'allowing',\n",
       " 'a',\n",
       " 'designer',\n",
       " 'to',\n",
       " 'input',\n",
       " 'example',\n",
       " 'usage',\n",
       " 'sentences',\n",
       " 'and',\n",
       " 'build',\n",
       " 'an',\n",
       " 'NLU',\n",
       " 'model',\n",
       " 'based',\n",
       " 'on',\n",
       " 'presented',\n",
       " 'matches',\n",
       " 'to',\n",
       " 'those',\n",
       " 'example',\n",
       " 'sentences',\n",
       " '.',\n",
       " 'In',\n",
       " 'one',\n",
       " 'embodiment',\n",
       " ',',\n",
       " 'a',\n",
       " 'method',\n",
       " 'for',\n",
       " 'initializing',\n",
       " 'a',\n",
       " 'workspace',\n",
       " 'for',\n",
       " 'building',\n",
       " 'an',\n",
       " 'NLU',\n",
       " 'system',\n",
       " 'includes',\n",
       " 'parsing',\n",
       " 'a',\n",
       " 'sample',\n",
       " 'sentence',\n",
       " 'to',\n",
       " 'select',\n",
       " 'at',\n",
       " 'least',\n",
       " 'one',\n",
       " 'candidate',\n",
       " 'stub',\n",
       " 'grammar',\n",
       " 'from',\n",
       " 'among',\n",
       " 'multiple',\n",
       " 'candidate',\n",
       " 'stub',\n",
       " 'grammars',\n",
       " '.',\n",
       " 'The',\n",
       " 'method',\n",
       " 'can',\n",
       " 'include',\n",
       " 'presenting',\n",
       " ',',\n",
       " 'to',\n",
       " 'a',\n",
       " 'user',\n",
       " ',',\n",
       " 'respective',\n",
       " 'representations',\n",
       " 'of',\n",
       " 'the',\n",
       " 'candidate',\n",
       " 'stub',\n",
       " 'grammars',\n",
       " 'selected',\n",
       " 'by',\n",
       " 'the',\n",
       " 'parsing',\n",
       " 'of',\n",
       " 'the',\n",
       " 'sample',\n",
       " 'sentence',\n",
       " '.',\n",
       " 'The',\n",
       " 'method',\n",
       " 'can',\n",
       " 'include',\n",
       " 'enabling',\n",
       " 'the',\n",
       " 'user',\n",
       " 'to',\n",
       " 'choose',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'respective',\n",
       " 'representations',\n",
       " 'of',\n",
       " 'the',\n",
       " 'candidate',\n",
       " 'stub',\n",
       " 'grammars',\n",
       " '.',\n",
       " 'The',\n",
       " 'method',\n",
       " 'can',\n",
       " 'include',\n",
       " 'adding',\n",
       " 'to',\n",
       " 'the',\n",
       " 'workspace',\n",
       " 'a',\n",
       " 'stub',\n",
       " 'grammar',\n",
       " 'corresponding',\n",
       " 'to',\n",
       " 'the',\n",
       " 'representation',\n",
       " 'of',\n",
       " 'the',\n",
       " 'candidate',\n",
       " 'stub',\n",
       " 'grammar',\n",
       " 'chosen',\n",
       " 'by',\n",
       " 'the',\n",
       " 'user',\n",
       " '.']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all tokens that are not alphabetic\n",
    "for patent in data:\n",
    "    words = [w.lower() for w in document if w.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['initializing',\n",
       " 'a',\n",
       " 'workspace',\n",
       " 'for',\n",
       " 'building',\n",
       " 'a',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'understanding',\n",
       " 'system',\n",
       " 'designing',\n",
       " 'a',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'understanding',\n",
       " 'nlu',\n",
       " 'model',\n",
       " 'for',\n",
       " 'an',\n",
       " 'application',\n",
       " 'from',\n",
       " 'scratch',\n",
       " 'can',\n",
       " 'be',\n",
       " 'difficult',\n",
       " 'for',\n",
       " 'a',\n",
       " 'system',\n",
       " 'can',\n",
       " 'simplify',\n",
       " 'the',\n",
       " 'design',\n",
       " 'process',\n",
       " 'by',\n",
       " 'providing',\n",
       " 'an',\n",
       " 'interface',\n",
       " 'allowing',\n",
       " 'a',\n",
       " 'designer',\n",
       " 'to',\n",
       " 'input',\n",
       " 'example',\n",
       " 'usage',\n",
       " 'sentences',\n",
       " 'and',\n",
       " 'build',\n",
       " 'an',\n",
       " 'nlu',\n",
       " 'model',\n",
       " 'based',\n",
       " 'on',\n",
       " 'presented',\n",
       " 'matches',\n",
       " 'to',\n",
       " 'those',\n",
       " 'example',\n",
       " 'sentences',\n",
       " 'in',\n",
       " 'one',\n",
       " 'embodiment',\n",
       " 'a',\n",
       " 'method',\n",
       " 'for',\n",
       " 'initializing',\n",
       " 'a',\n",
       " 'workspace',\n",
       " 'for',\n",
       " 'building',\n",
       " 'an',\n",
       " 'nlu',\n",
       " 'system',\n",
       " 'includes',\n",
       " 'parsing',\n",
       " 'a',\n",
       " 'sample',\n",
       " 'sentence',\n",
       " 'to',\n",
       " 'select',\n",
       " 'at',\n",
       " 'least',\n",
       " 'one',\n",
       " 'candidate',\n",
       " 'stub',\n",
       " 'grammar',\n",
       " 'from',\n",
       " 'among',\n",
       " 'multiple',\n",
       " 'candidate',\n",
       " 'stub',\n",
       " 'grammars',\n",
       " 'the',\n",
       " 'method',\n",
       " 'can',\n",
       " 'include',\n",
       " 'presenting',\n",
       " 'to',\n",
       " 'a',\n",
       " 'user',\n",
       " 'respective',\n",
       " 'representations',\n",
       " 'of',\n",
       " 'the',\n",
       " 'candidate',\n",
       " 'stub',\n",
       " 'grammars',\n",
       " 'selected',\n",
       " 'by',\n",
       " 'the',\n",
       " 'parsing',\n",
       " 'of',\n",
       " 'the',\n",
       " 'sample',\n",
       " 'sentence',\n",
       " 'the',\n",
       " 'method',\n",
       " 'can',\n",
       " 'include',\n",
       " 'enabling',\n",
       " 'the',\n",
       " 'user',\n",
       " 'to',\n",
       " 'choose',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'respective',\n",
       " 'representations',\n",
       " 'of',\n",
       " 'the',\n",
       " 'candidate',\n",
       " 'stub',\n",
       " 'grammars',\n",
       " 'the',\n",
       " 'method',\n",
       " 'can',\n",
       " 'include',\n",
       " 'adding',\n",
       " 'to',\n",
       " 'the',\n",
       " 'workspace',\n",
       " 'a',\n",
       " 'stub',\n",
       " 'grammar',\n",
       " 'corresponding',\n",
       " 'to',\n",
       " 'the',\n",
       " 'representation',\n",
       " 'of',\n",
       " 'the',\n",
       " 'candidate',\n",
       " 'stub',\n",
       " 'grammar',\n",
       " 'chosen',\n",
       " 'by',\n",
       " 'the',\n",
       " 'user']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words\n",
    "# note that there is word loss here, e.g. the word non-expert, which contains a hypothesis, appears excluded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turns positive integers (indexes) into dense vectors of fixed size.\n",
    "# The Embedding layer takes at least two arguments:\n",
    "# the number of possible words in the vocabulary, here 1000 (1 + maximum word index),\n",
    "# and the dimensionality of the embeddings, here 32.\n",
    "embedding_layer = layers.Embedding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embedding_layer = layers.Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
